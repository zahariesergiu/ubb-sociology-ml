{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUUVrx70Z5KL"
      },
      "source": [
        "Permutation Feature Importance on the [wine dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) using scikit-learn. In particular you will:\n",
        "\n",
        "\n",
        "1. Train a Random Forest classifier on the data.\n",
        "2. Compute the feature importance score by permutating each feature.\n",
        "3. Re-train the model with only the top features.\n",
        "4. Check other classifiers for comparison.\n",
        "\n",
        "Let's get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxXreDg0tGOF"
      },
      "source": [
        "## Inspect and pre-process the data\n",
        "\n",
        "Begin by upgrading scikit-learn to the latest version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UsGnA3r9DQkw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in e:\\master\\adc\\14.machine_learning\\.venv\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in e:\\master\\adc\\14.machine_learning\\.venv\\lib\\site-packages (from scikit-learn) (2.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in e:\\master\\adc\\14.machine_learning\\.venv\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in e:\\master\\adc\\14.machine_learning\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\master\\adc\\14.machine_learning\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx9r-xd5tWZO"
      },
      "source": [
        "Now import the required dependencies and load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "DCRACaLFC-1N",
        "outputId": "b014f0b1-2a91-4c9c-f92a-3c6c6203a75a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "\n",
              "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0        3.06                  0.28             2.29             5.64  1.04   \n",
              "1        2.76                  0.26             1.28             4.38  1.05   \n",
              "2        3.24                  0.30             2.81             5.68  1.03   \n",
              "3        3.49                  0.24             2.18             7.80  0.86   \n",
              "4        2.69                  0.39             1.82             4.32  1.04   \n",
              "\n",
              "   od280/od315_of_diluted_wines  proline  target  \n",
              "0                          3.92   1065.0       0  \n",
              "1                          3.40   1050.0       0  \n",
              "2                          3.17   1185.0       0  \n",
              "3                          3.45   1480.0       0  \n",
              "4                          2.93    735.0       0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# as_frame param requires scikit-learn >= 0.23\n",
        "data = load_wine(as_frame=True)\n",
        "\n",
        "\n",
        "# Print first rows of the data\n",
        "data.frame.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Aaszrn9CEsIf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Train / Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)\n",
        "\n",
        "# Instantiate StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit it to the train data\n",
        "scaler.fit(X_train)\n",
        "\n",
        "\n",
        "# Use it to transform the train and test data\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "\n",
        "# Notice that the scaler is trained on the train data to avoid data leakage from the test set\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVmae4rtvGiA"
      },
      "source": [
        "## Train the classifier\n",
        "\n",
        "Now you will fit a [Random Forest classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) with 10 estimators and compute the mean accuracy achieved:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK5Dxa70Ir3N",
        "outputId": "112f71c5-93b8-4130-d803-e2400a8bd4d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9111111111111111"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Fit the classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=10, random_state=42).fit(X_train, y_train) # n_estimators = number of trees in the forest.\n",
        "\n",
        "# Print the mean accuracy achieved by the classifier on the test set\n",
        "rf_clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_RPyB9Owfms"
      },
      "source": [
        "## Permutation Feature Importance\n",
        "\n",
        "To perform the model inspection technique known as Permutation Feature Importance you will use scikit-learn's built-in function [`permutation_importance`](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance).\n",
        "\n",
        "You will create a function that given a classifier, features and labels computes the feature importance for every feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nAvDl_2rJsTA"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "def feature_importance(clf, X, y, top_limit=None):\n",
        "\n",
        "  # Retrieve the Bunch object after 50 repeats\n",
        "  # n_repeats is the number of times that each feature was permuted to compute the final score\n",
        "  bunch = permutation_importance(clf, X, y,\n",
        "                                 n_repeats=50, random_state=42)\n",
        "\n",
        "  # Average feature importance\n",
        "  imp_means = bunch.importances_mean\n",
        "\n",
        "  # List that contains the index of each feature in descending order of importance\n",
        "  ordered_imp_means_args = np.argsort(imp_means)[::-1]\n",
        "\n",
        "  # If no limit print all features\n",
        "  if top_limit is None:\n",
        "    top_limit = len(ordered_imp_means_args)\n",
        "\n",
        "  # Print relevant information\n",
        "  for i, _ in zip(ordered_imp_means_args, range(top_limit)):\n",
        "    name = data.feature_names[i]\n",
        "    imp_score = imp_means[i]\n",
        "    imp_std = bunch.importances_std[i]\n",
        "    print(f\"Feature {name} with index {i} has an average importance score of {imp_score:.3f} +/- {imp_std:.3f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCHWbK_3yeJ_"
      },
      "source": [
        "The importance score is computed in a way that higher values represent better predictive power. To know exactly how it is computed check out this [link](https://scikit-learn.org/stable/modules/permutation_importance.html#outline-of-the-permutation-importance-algorithm).\n",
        "\n",
        "Now use the `feature_importance` function on the Random Forest classifier and the train set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuB6EyTuHT7S",
        "outputId": "a44f3b1c-aa2c-4687-a022-bdbb92c94e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature flavanoids with index 6 has an average importance score of 0.227 +/- 0.025\n",
            "\n",
            "Feature proline with index 12 has an average importance score of 0.142 +/- 0.019\n",
            "\n",
            "Feature color_intensity with index 9 has an average importance score of 0.112 +/- 0.023\n",
            "\n",
            "Feature od280/od315_of_diluted_wines with index 11 has an average importance score of 0.007 +/- 0.005\n",
            "\n",
            "Feature total_phenols with index 5 has an average importance score of 0.003 +/- 0.004\n",
            "\n",
            "Feature malic_acid with index 1 has an average importance score of 0.002 +/- 0.004\n",
            "\n",
            "Feature proanthocyanins with index 8 has an average importance score of 0.002 +/- 0.003\n",
            "\n",
            "Feature hue with index 10 has an average importance score of 0.002 +/- 0.003\n",
            "\n",
            "Feature nonflavanoid_phenols with index 7 has an average importance score of 0.000 +/- 0.000\n",
            "\n",
            "Feature magnesium with index 4 has an average importance score of 0.000 +/- 0.000\n",
            "\n",
            "Feature alcalinity_of_ash with index 3 has an average importance score of 0.000 +/- 0.000\n",
            "\n",
            "Feature ash with index 2 has an average importance score of 0.000 +/- 0.000\n",
            "\n",
            "Feature alcohol with index 0 has an average importance score of 0.000 +/- 0.000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Apply feature importance function\n",
        "feature_importance(rf_clf, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt5DOAE_wG40",
        "outputId": "58a743d4-169e-495e-b704-77b45662f950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature flavanoids with index 6 has an average importance score of 0.202 +/- 0.047\n",
            "\n",
            "Feature proline with index 12 has an average importance score of 0.143 +/- 0.042\n",
            "\n",
            "Feature color_intensity with index 9 has an average importance score of 0.112 +/- 0.043\n",
            "\n",
            "Feature alcohol with index 0 has an average importance score of 0.024 +/- 0.017\n",
            "\n",
            "Feature magnesium with index 4 has an average importance score of 0.021 +/- 0.015\n",
            "\n",
            "Feature od280/od315_of_diluted_wines with index 11 has an average importance score of 0.015 +/- 0.018\n",
            "\n",
            "Feature hue with index 10 has an average importance score of 0.013 +/- 0.018\n",
            "\n",
            "Feature total_phenols with index 5 has an average importance score of 0.002 +/- 0.016\n",
            "\n",
            "Feature nonflavanoid_phenols with index 7 has an average importance score of 0.000 +/- 0.000\n",
            "\n",
            "Feature alcalinity_of_ash with index 3 has an average importance score of 0.000 +/- 0.000\n",
            "\n",
            "Feature malic_acid with index 1 has an average importance score of -0.002 +/- 0.017\n",
            "\n",
            "Feature ash with index 2 has an average importance score of -0.003 +/- 0.008\n",
            "\n",
            "Feature proanthocyanins with index 8 has an average importance score of -0.021 +/- 0.020\n",
            "\n"
          ]
        }
      ],
      "source": [
        "feature_importance(rf_clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpHC8q3y8byl"
      },
      "source": [
        "### Re-train the model with the most important features\n",
        "\n",
        "Now you will re-train the Random Forest classifier with only the top 3 most important features.\n",
        "\n",
        "In this case they are the same for both sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daZkt0PE1oxc",
        "outputId": "eb6d7bce-da9b-40d9-9df9-7c5c4e0c606e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On TRAIN split:\n",
            "\n",
            "Feature flavanoids with index 6 has an average importance score of 0.227 +/- 0.025\n",
            "\n",
            "Feature proline with index 12 has an average importance score of 0.142 +/- 0.019\n",
            "\n",
            "Feature color_intensity with index 9 has an average importance score of 0.112 +/- 0.023\n",
            "\n",
            "\n",
            "On TEST split:\n",
            "\n",
            "Feature flavanoids with index 6 has an average importance score of 0.202 +/- 0.047\n",
            "\n",
            "Feature proline with index 12 has an average importance score of 0.143 +/- 0.042\n",
            "\n",
            "Feature color_intensity with index 9 has an average importance score of 0.112 +/- 0.043\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"On TRAIN split:\\n\")\n",
        "feature_importance(rf_clf, X_train, y_train, top_limit=3)\n",
        "\n",
        "print(\"\\nOn TEST split:\\n\")\n",
        "feature_importance(rf_clf, X_test, y_test, top_limit=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOZyil7eqH5-",
        "outputId": "f337eb19-ce5f-4b61-d077-57db75a0fe06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preserve only the top features\n",
        "X_train_top_features = X_train[:,[6, 9, 12]]\n",
        "X_test_top_features = X_test[:,[6, 9, 12]]\n",
        "\n",
        "# Re-train with only these features\n",
        "rf_clf = RandomForestClassifier(n_estimators=10, random_state=42).fit(X_train_top_features, y_train)\n",
        "\n",
        "\n",
        "# Compute mean accuracy achieved\n",
        "rf_clf.score(X_test_top_features, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b72FJLpj9Aly",
        "outputId": "0842a8bc-26eb-440f-afe3-3c2bcd43f169"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 0.95 acc\n",
        "# Preserve only the top 3 features\n",
        "X_train_top_features = X_train[:,[0, 6, 9, 12]]\n",
        "X_test_top_features = X_test[:,[0, 6, 9, 12]]\n",
        "\n",
        "# Re-train with only these features\n",
        "rf_clf = RandomForestClassifier(n_estimators=10, random_state=42).fit(X_train_top_features, y_train)\n",
        "\n",
        "\n",
        "# Compute mean accuracy achieved\n",
        "rf_clf.score(X_test_top_features, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGqKd5c7-Jaw"
      },
      "source": [
        "### Try out other classifiers\n",
        "\n",
        "The process of Permutation Feature Importance is also dependant on the classifier you are using. Since different classifiers follow different rules for classification it is natural to assume they will consider different features to be important or unimportant.\n",
        "\n",
        "To test this, try out other classifiers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv6oXNMUrzmR",
        "outputId": "104d5247-b1a8-4327-e658-b2bb0946d0c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "➡️ Laso classifier\n",
            "\n",
            "📏 Mean accuracy score on the test set: 86.80%\n",
            "\n",
            "🔝 Top 4 features when using the test set:\n",
            "\n",
            "Feature flavanoids with index 6 has an average importance score of 0.323 +/- 0.055\n",
            "\n",
            "Feature proline with index 12 has an average importance score of 0.203 +/- 0.035\n",
            "\n",
            "Feature od280/od315_of_diluted_wines with index 11 has an average importance score of 0.146 +/- 0.030\n",
            "\n",
            "Feature alcalinity_of_ash with index 3 has an average importance score of 0.038 +/- 0.014\n",
            "\n",
            "====================================================================================================\n",
            "➡️ Ridge classifier\n",
            "\n",
            "📏 Mean accuracy score on the test set: 88.71%\n",
            "\n",
            "🔝 Top 4 features when using the test set:\n",
            "\n",
            "Feature flavanoids with index 6 has an average importance score of 0.445 +/- 0.071\n",
            "\n",
            "Feature proline with index 12 has an average importance score of 0.210 +/- 0.035\n",
            "\n",
            "Feature color_intensity with index 9 has an average importance score of 0.119 +/- 0.029\n",
            "\n",
            "Feature od280/od315_of_diluted_wines with index 11 has an average importance score of 0.111 +/- 0.026\n",
            "\n",
            "====================================================================================================\n",
            "➡️ Decision Tree classifier\n",
            "\n",
            "📏 Mean accuracy score on the test set: 93.33%\n",
            "\n",
            "🔝 Top 4 features when using the test set:\n",
            "\n",
            "Feature flavanoids with index 6 has an average importance score of 0.297 +/- 0.061\n",
            "\n",
            "Feature color_intensity with index 9 has an average importance score of 0.206 +/- 0.046\n",
            "\n",
            "Feature proline with index 12 has an average importance score of 0.198 +/- 0.038\n",
            "\n",
            "Feature malic_acid with index 1 has an average importance score of 0.008 +/- 0.012\n",
            "\n",
            "====================================================================================================\n",
            "➡️ Support Vector classifier\n",
            "\n",
            "📏 Mean accuracy score on the test set: 97.78%\n",
            "\n",
            "🔝 Top 4 features when using the test set:\n",
            "\n",
            "Feature proline with index 12 has an average importance score of 0.069 +/- 0.031\n",
            "\n",
            "Feature flavanoids with index 6 has an average importance score of 0.061 +/- 0.023\n",
            "\n",
            "Feature alcohol with index 0 has an average importance score of 0.044 +/- 0.023\n",
            "\n",
            "Feature ash with index 2 has an average importance score of 0.032 +/- 0.018\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Select 4 new classifiers\n",
        "clfs = {\"Laso\": Lasso(alpha=0.05),\n",
        "        \"Ridge\": Ridge(),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(),\n",
        "        \"Support Vector\": SVC()}\n",
        "\n",
        "\n",
        "# Compute feature importance on the test set given a classifier\n",
        "def fit_compute_importance(clf):\n",
        "  clf.fit(X_train, y_train)\n",
        "  print(f\"📏 Mean accuracy score on the test set: {clf.score(X_test, y_test)*100:.2f}%\\n\")\n",
        "  print(\"🔝 Top 4 features when using the test set:\\n\")\n",
        "  feature_importance(clf, X_test, y_test, top_limit=4)\n",
        "\n",
        "\n",
        "# Print results\n",
        "for name, clf in clfs.items():\n",
        "  print(\"=====\"*20)\n",
        "  print(f\"➡️ {name} classifier\\n\")\n",
        "  fit_compute_importance(clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwRlO14nZ_nY"
      },
      "source": [
        "-----------------------------\n",
        "**Congratulations on finishing lab!** Now you should have a clearer understanding of what Permutation Feature Importance is, why it is useful and how to implement this technique using scikit-learn.\n",
        "\n",
        "**Keep it up!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnbG2qskLeJR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KxXreDg0tGOF",
        "BVmae4rtvGiA"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
