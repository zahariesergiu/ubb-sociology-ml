{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydHb_ZL5yy6f"
      },
      "source": [
        "# **Final Project Task 4 - Census Modeling Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnzXS8Oo9jwY"
      },
      "source": [
        "Requirements:\n",
        "\n",
        "Load Data\n",
        "- Use the preprocessed dataset from Task 1.\n",
        "\n",
        "Prepare Features\n",
        "- Feature Selection:\n",
        "    - Select relevant numerical and categorical features.\n",
        "    - Note: K-Means works best with numerical data.\n",
        "- Data Preprocessing:\n",
        "    - Be sure you have normalized numerical features (e.g., using MinMaxScaler or StandardScaler) and categorical features encoded properly (e.g., One-Hot Encoding or Ordinal Encoding).\n",
        "    \n",
        "Clustering Model Implementation\n",
        "- Apply K-Means Clustering:\n",
        "    - Experiment with different values of K (number of clusters).\n",
        "    - Use the Elbow Method to determine the optimal number of clusters:\n",
        "    - Use yellowbrick.cluster.KElbowVisualizer to find the best K.\n",
        "    - Calculate the Silhouette Score to evaluate cluster separation.\n",
        "- Alternative Clustering Approaches:\n",
        "    - Experiment with Hierarchical Clustering.\n",
        "    - Experiment with DBSCAN\n",
        "\n",
        "Visualize & Interpret Clusters\n",
        "- Dimensionality Reduction:\n",
        "    - Apply PCA or t-SNE to reduce dimensions and visualize clusters in 2D.\n",
        "- Cluster Analysis:\n",
        "    - Plot the clusters in 2D space.\n",
        "    - Identify key characteristics of each group.\n",
        "    - Use only numerical variables to interpret the clusters.\n",
        "- Example insights:\n",
        "    - \"Older individuals tend to work fewer hours per week.\"\n",
        "    - \"High-income individuals belong to a specific cluster.\"\n",
        "\n",
        "Evaluate Cluster Quality\n",
        "- Silhouette Score:\n",
        "    - Compute the Silhouette Score to measure cluster compactness and separation. Higher values indicate better clustering results.\n",
        "- Cluster Distribution:\n",
        "    - Analyze how well the data points are distributed across clusters.\n",
        "\n",
        "\n",
        "Deliverables:\n",
        "- Notebook code with no errors.\n",
        "- Visualizations & Analysis:\n",
        "- Elbow method plot for K selection.\n",
        "- 2D visualization of clusters.\n",
        "- Summary of cluster characteristics.\n",
        "- Cluster evaluation metrics (Silhouette Score).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xifylnglyn2W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "CzWyJfHkyn-8",
        "outputId": "633344dd-56a2-44a7-a237-a26873898c80"
      },
      "outputs": [],
      "source": [
        "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
        "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
        "    \"hours-per-week\", \"native-country\", \"income\"\n",
        "]\n",
        "\n",
        "data = pd.read_csv(data_url, header=None, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
        "data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of using KElbowVisualizer\n",
        "\n",
        "# from yellowbrick.cluster import KElbowVisualizer\n",
        "# visualizer = KElbowVisualizer(clustering_model, k=(2, 10), metric='distortion', timings=False)\n",
        "# visualizer.fit(preprocessed_data)\n",
        "# visualizer.show()\n",
        "# optimal_k = visualizer.elbow_value_\n",
        "\n",
        "\n",
        "# Example of using PCA\n",
        "\n",
        "# from sklearn.decomposition import PCA\n",
        "# clusters = clustering_model.fit_predict(preprocessed_data)\n",
        "# pca = PCA(n_components=2)\n",
        "# pca_result = pca.fit_transform(preprocessed_data)\n",
        "# pca1 = pca_result[:, 0]\n",
        "# pca2 = pca_result[:, 1]\n",
        "# # Visualizing Clusters\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.scatterplot(x=pca1, y=pca2, hue=clusters, palette='tab10', data=data, alpha=0.7)\n",
        "# plt.title(f'PCA Projection of Clusters (K={num_clusters})')\n",
        "# plt.xlabel('Principal Component 1')\n",
        "# plt.ylabel('Principal Component 2')\n",
        "# plt.legend(title='Cluster')\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
