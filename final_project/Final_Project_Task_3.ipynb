{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final Project Task 3 - Census Modeling Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20646</th>\n",
       "      <td>19</td>\n",
       "      <td>?</td>\n",
       "      <td>117201</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14742</th>\n",
       "      <td>31</td>\n",
       "      <td>?</td>\n",
       "      <td>163890</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3766</th>\n",
       "      <td>37</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>264503</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22991</th>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>198841</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32049</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>313835</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12582</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>193285</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>27</td>\n",
       "      <td>?</td>\n",
       "      <td>330132</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>38</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>307404</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>26</td>\n",
       "      <td>Private</td>\n",
       "      <td>386585</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19880</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>186239</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age    workclass  fnlwgt     education  education-num  \\\n",
       "20646   19            ?  117201  Some-college             10   \n",
       "14742   31            ?  163890  Some-college             10   \n",
       "3766    37    Local-gov  264503       HS-grad              9   \n",
       "22991   36      Private  198841       Masters             14   \n",
       "32049   32      Private  313835       Masters             14   \n",
       "12582   31      Private  193285     Bachelors             13   \n",
       "5228    27            ?  330132       HS-grad              9   \n",
       "8904    38  Federal-gov  307404  Some-college             10   \n",
       "2302    26      Private  386585  Some-college             10   \n",
       "19880   28      Private  186239  Some-college             10   \n",
       "\n",
       "           marital-status       occupation   relationship   race     sex  \\\n",
       "20646       Never-married                ?      Own-child  White    Male   \n",
       "14742       Never-married                ?      Unmarried  Black  Female   \n",
       "3766   Married-civ-spouse  Protective-serv        Husband  White    Male   \n",
       "22991  Married-civ-spouse  Exec-managerial        Husband  White    Male   \n",
       "32049  Married-civ-spouse   Prof-specialty        Husband  White    Male   \n",
       "12582       Never-married   Prof-specialty  Not-in-family  White    Male   \n",
       "5228        Never-married                ?  Not-in-family  White  Female   \n",
       "8904             Divorced     Adm-clerical      Unmarried  White  Female   \n",
       "2302             Divorced     Tech-support  Not-in-family  White    Male   \n",
       "19880       Never-married     Adm-clerical      Unmarried  Black  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "20646             0             0              22  United-States  <=50K  \n",
       "14742             0             0              40  United-States  <=50K  \n",
       "3766              0             0              40  United-States  <=50K  \n",
       "22991             0             0              40  United-States   >50K  \n",
       "32049             0             0              40  United-States   >50K  \n",
       "12582             0             0              40  United-States  <=50K  \n",
       "5228              0             0              25  United-States  <=50K  \n",
       "8904              0             0              40  United-States  <=50K  \n",
       "2302              0             0              60  United-States  <=50K  \n",
       "19880             0             0              40  United-States  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "columns = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "data = pd.read_csv(data_url, header=None, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, HuberRegressor, Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "      <th>age_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16501</th>\n",
       "      <td>40</td>\n",
       "      <td>1.913489</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26428</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.903523</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>-0.031360</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>69</td>\n",
       "      <td>4.159408</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>-0.031360</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-1.655225</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8943</th>\n",
       "      <td>22</td>\n",
       "      <td>-0.391739</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>18-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19250</th>\n",
       "      <td>54</td>\n",
       "      <td>-0.166780</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>-0.031360</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>45-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23960</th>\n",
       "      <td>37</td>\n",
       "      <td>-1.393990</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>32</td>\n",
       "      <td>0.078539</td>\n",
       "      <td>11th</td>\n",
       "      <td>-1.197459</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>33</td>\n",
       "      <td>-0.237146</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10820</th>\n",
       "      <td>39</td>\n",
       "      <td>0.107312</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.845327</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>43</td>\n",
       "      <td>-0.658479</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23015</th>\n",
       "      <td>42</td>\n",
       "      <td>0.219005</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>4.466257</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17864</th>\n",
       "      <td>25</td>\n",
       "      <td>1.746921</td>\n",
       "      <td>12th</td>\n",
       "      <td>-0.808759</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>1.584366</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>18-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14734</th>\n",
       "      <td>30</td>\n",
       "      <td>-1.065979</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>1.584366</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11834</th>\n",
       "      <td>33</td>\n",
       "      <td>0.739762</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>-0.031360</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23279</th>\n",
       "      <td>50</td>\n",
       "      <td>0.042186</td>\n",
       "      <td>Masters</td>\n",
       "      <td>1.523438</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>45-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30373</th>\n",
       "      <td>36</td>\n",
       "      <td>3.233368</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>4.503482</td>\n",
       "      <td>0.612489</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>44</td>\n",
       "      <td>-0.206762</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26089</th>\n",
       "      <td>57</td>\n",
       "      <td>-0.613732</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>1.912138</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.440378</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>55-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27798</th>\n",
       "      <td>44</td>\n",
       "      <td>-0.086874</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>-0.031360</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>0.126550</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5235</th>\n",
       "      <td>22</td>\n",
       "      <td>0.772117</td>\n",
       "      <td>11th</td>\n",
       "      <td>-1.197459</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.14592</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>18-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age    fnlwgt     education  education-num  sex  capital-gain  \\\n",
       "16501   40  1.913489       HS-grad      -0.420060    0      -0.14592   \n",
       "26428   34 -0.903523  Some-college      -0.031360    1      -0.14592   \n",
       "4729    69  4.159408  Some-college      -0.031360    0      -0.14592   \n",
       "8943    22 -0.391739       HS-grad      -0.420060    0      -0.14592   \n",
       "19250   54 -0.166780  Some-college      -0.031360    1      -0.14592   \n",
       "23960   37 -1.393990       HS-grad      -0.420060    1      -0.14592   \n",
       "22873   32  0.078539          11th      -1.197459    1      -0.14592   \n",
       "5573    33 -0.237146     Bachelors       1.134739    1      -0.14592   \n",
       "10820   39  0.107312     Bachelors       1.134739    0      -0.14592   \n",
       "7536    43 -0.658479       HS-grad      -0.420060    1      -0.14592   \n",
       "23015   42  0.219005     Bachelors       1.134739    1      -0.14592   \n",
       "17864   25  1.746921          12th      -0.808759    1      -0.14592   \n",
       "14734   30 -1.065979       HS-grad      -0.420060    1      -0.14592   \n",
       "11834   33  0.739762  Some-college      -0.031360    1      -0.14592   \n",
       "23279   50  0.042186       Masters       1.523438    0      -0.14592   \n",
       "30373   36  3.233368       HS-grad      -0.420060    1      -0.14592   \n",
       "2268    44 -0.206762       HS-grad      -0.420060    1      -0.14592   \n",
       "26089   57 -0.613732   Prof-school       1.912138    1      -0.14592   \n",
       "27798   44 -0.086874  Some-college      -0.031360    1      -0.14592   \n",
       "5235    22  0.772117          11th      -1.197459    0      -0.14592   \n",
       "\n",
       "       capital-loss  hours-per-week  income  workclass_Local-gov  ...  \\\n",
       "16501     -0.216660       -0.035429       0                False  ...   \n",
       "26428     -0.216660       -0.035429       0                False  ...   \n",
       "4729      -0.216660       -1.655225       0                False  ...   \n",
       "8943      -0.216660       -0.035429       0                False  ...   \n",
       "19250     -0.216660       -0.035429       1                False  ...   \n",
       "23960     -0.216660       -0.035429       0                False  ...   \n",
       "22873     -0.216660       -0.035429       0                False  ...   \n",
       "5573      -0.216660       -0.035429       0                False  ...   \n",
       "10820     -0.216660       -0.845327       0                False  ...   \n",
       "7536      -0.216660       -0.035429       1                False  ...   \n",
       "23015      4.466257       -0.035429       1                False  ...   \n",
       "17864     -0.216660        1.584366       0                False  ...   \n",
       "14734     -0.216660        1.584366       0                False  ...   \n",
       "11834     -0.216660       -0.035429       0                 True  ...   \n",
       "23279     -0.216660       -0.035429       1                False  ...   \n",
       "30373      4.503482        0.612489       1                False  ...   \n",
       "2268      -0.216660       -0.035429       0                False  ...   \n",
       "26089     -0.216660       -0.440378       1                False  ...   \n",
       "27798     -0.216660        0.126550       0                False  ...   \n",
       "5235      -0.216660       -0.035429       0                False  ...   \n",
       "\n",
       "       native-country_Puerto-Rico  native-country_Scotland  \\\n",
       "16501                       False                    False   \n",
       "26428                       False                    False   \n",
       "4729                        False                    False   \n",
       "8943                        False                    False   \n",
       "19250                       False                    False   \n",
       "23960                       False                    False   \n",
       "22873                       False                    False   \n",
       "5573                        False                    False   \n",
       "10820                       False                    False   \n",
       "7536                        False                    False   \n",
       "23015                       False                    False   \n",
       "17864                       False                    False   \n",
       "14734                       False                    False   \n",
       "11834                       False                    False   \n",
       "23279                       False                    False   \n",
       "30373                       False                    False   \n",
       "2268                        False                    False   \n",
       "26089                       False                    False   \n",
       "27798                       False                    False   \n",
       "5235                        False                    False   \n",
       "\n",
       "       native-country_South  native-country_Taiwan  native-country_Thailand  \\\n",
       "16501                 False                  False                    False   \n",
       "26428                 False                  False                    False   \n",
       "4729                  False                  False                    False   \n",
       "8943                  False                  False                    False   \n",
       "19250                 False                  False                    False   \n",
       "23960                 False                  False                    False   \n",
       "22873                 False                  False                    False   \n",
       "5573                  False                  False                    False   \n",
       "10820                 False                  False                    False   \n",
       "7536                  False                  False                    False   \n",
       "23015                 False                  False                    False   \n",
       "17864                 False                  False                    False   \n",
       "14734                 False                  False                    False   \n",
       "11834                 False                  False                    False   \n",
       "23279                 False                  False                    False   \n",
       "30373                 False                  False                    False   \n",
       "2268                  False                  False                    False   \n",
       "26089                 False                  False                    False   \n",
       "27798                 False                  False                    False   \n",
       "5235                  False                  False                    False   \n",
       "\n",
       "       native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "16501                           False                          True   \n",
       "26428                           False                          True   \n",
       "4729                            False                          True   \n",
       "8943                            False                          True   \n",
       "19250                           False                          True   \n",
       "23960                           False                          True   \n",
       "22873                           False                          True   \n",
       "5573                            False                          True   \n",
       "10820                           False                          True   \n",
       "7536                            False                          True   \n",
       "23015                           False                          True   \n",
       "17864                           False                         False   \n",
       "14734                           False                          True   \n",
       "11834                           False                          True   \n",
       "23279                           False                          True   \n",
       "30373                           False                          True   \n",
       "2268                            False                         False   \n",
       "26089                           False                          True   \n",
       "27798                           False                          True   \n",
       "5235                            False                          True   \n",
       "\n",
       "       native-country_Vietnam  native-country_Yugoslavia  age_bin  \n",
       "16501                   False                      False    35-44  \n",
       "26428                   False                      False    25-34  \n",
       "4729                    False                      False      65+  \n",
       "8943                    False                      False    18-24  \n",
       "19250                   False                      False    45-54  \n",
       "23960                   False                      False    35-44  \n",
       "22873                   False                      False    25-34  \n",
       "5573                    False                      False    25-34  \n",
       "10820                   False                      False    35-44  \n",
       "7536                    False                      False    35-44  \n",
       "23015                   False                      False    35-44  \n",
       "17864                   False                      False    18-24  \n",
       "14734                   False                      False    25-34  \n",
       "11834                   False                      False    25-34  \n",
       "23279                   False                      False    45-54  \n",
       "30373                   False                      False    35-44  \n",
       "2268                    False                      False    35-44  \n",
       "26089                   False                      False    55-64  \n",
       "27798                   False                      False    35-44  \n",
       "5235                    False                      False    18-24  \n",
       "\n",
       "[20 rows x 86 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the dataset we will be working on \n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Simina\\\\OneDrive\\\\ADC\\\\ML1\\\\ubb-sociology-ml\\\\final_project\\\\data_normalized.csv\")\n",
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "target_column = 'hours-per-week'\n",
    "## Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['hours-per-week'])\n",
    "y = data['hours-per-week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data in 3 sets for train, validation and test - 60% train, 20% validation, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical and categorical data \n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            MSE       MAE        R²\n",
      "SGDRegressor           0.852521  0.641523  0.160513\n",
      "DecisionTreeRegressor  1.620170  0.871664 -0.595400\n",
      "RandomForestRegressor  0.937613  0.682281  0.076722\n",
      "Ridge                  0.847372  0.637008  0.165583\n",
      "Lasso                  1.015587  0.619802 -0.000060\n"
     ]
    }
   ],
   "source": [
    "# Define a function to evaluate models\n",
    "def evaluate_model(model):\n",
    "    # Create a pipeline that includes preprocessing, scaling, and model training\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),               \n",
    "        ('scaler', StandardScaler()),                 \n",
    "        ('model', model)                              \n",
    "    ])\n",
    "    \n",
    "    # Fit the model on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    return mse, mae, r2, pipeline\n",
    "\n",
    "# Initialize models with default settings\n",
    "models = {\n",
    "    'SGDRegressor': SGDRegressor(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso()\n",
    "}\n",
    "\n",
    "# Evaluate each model and store results\n",
    "results = {}\n",
    "pipelines = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mse, mae, r2, pipeline = evaluate_model(model)\n",
    "    results[name] = {'MSE': mse, 'MAE': mae, 'R²': r2}\n",
    "    pipelines[name] = pipeline\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression are cel mai mic MSE, ceea ce înseamnă că face cele mai mici erori pătratice în predicții.\n",
    "# DecisionTreeRegressor are cel mai mare MSE, sugerând overfitting \n",
    "\n",
    "# Lasso are cel mai mic MAE, ceea ce înseamnă că, în medie, predicțiile sale sunt cele mai apropiate de valorile reale.\n",
    "\n",
    "# Ridge Regression are cel mai bun R² (0.165), dar valoarea este totuși destul de mică, ceea ce sugerează că modelul este cel mai bun model de referință.\n",
    "# SGDRegressor are o performanță similară cu Ridge, ceea ce indică faptul că datele pot fi modelate liniar.\n",
    "# DecisionTreeRegressor și Lasso au R² negative, indicând o performanță slabă.\n",
    "\n",
    "-------------------------------------------------------------------------------------------\n",
    "\n",
    "# Overall, Ridge Regression pare să fie cel mai echilibrat model, având cele mai bune scoruri la MSE și R², ceea ce sugerează o performanță stabilă."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimente pentru Ridge:\n",
      "Configurația 1: Poly Degree=None, Scaling=None, Select K Best=None\n",
      "MSE: 0.8474, MAE: 0.6370, R²: 0.1656\n",
      "\n",
      "Configurația 2: Poly Degree=2, Scaling=standard, Select K Best=None\n",
      "MSE: 0.8029, MAE: 0.6198, R²: 0.2094\n",
      "\n",
      "Configurația 3: Poly Degree=None, Scaling=minmax, Select K Best=10\n",
      "MSE: 0.8640, MAE: 0.6420, R²: 0.1492\n",
      "\n",
      "Configurația 4: Poly Degree=2, Scaling=minmax, Select K Best=5\n",
      "MSE: 0.9301, MAE: 0.6438, R²: 0.0841\n",
      "\n",
      "Configurația 5: Poly Degree=3, Scaling=standard, Select K Best=None\n",
      "MSE: 1.0792, MAE: 0.6536, R²: -0.0627\n",
      "\n",
      "\n",
      "Experimente pentru Lasso:\n",
      "Configurația 1: Poly Degree=None, Scaling=None, Select K Best=None\n",
      "MSE: 1.0154, MAE: 0.6197, R²: 0.0001\n",
      "\n",
      "Configurația 2: Poly Degree=2, Scaling=standard, Select K Best=None\n",
      "MSE: 1.0156, MAE: 0.6198, R²: -0.0001\n",
      "\n",
      "Configurația 3: Poly Degree=None, Scaling=minmax, Select K Best=10\n",
      "MSE: 1.0156, MAE: 0.6198, R²: -0.0001\n",
      "\n",
      "Configurația 4: Poly Degree=2, Scaling=minmax, Select K Best=5\n",
      "MSE: 1.0156, MAE: 0.6198, R²: -0.0001\n",
      "\n",
      "Configurația 5: Poly Degree=3, Scaling=standard, Select K Best=None\n",
      "MSE: 0.9600, MAE: 0.6232, R²: 0.0547\n",
      "\n",
      "\n",
      "Experimente pentru SGDRegressor:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1608: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurația 1: Poly Degree=None, Scaling=None, Select K Best=None\n",
      "MSE: 175512719.5449, MAE: 7803.7458, R²: -172829347.6448\n",
      "\n",
      "Configurația 2: Poly Degree=2, Scaling=standard, Select K Best=None\n",
      "MSE: 22315842555526564901027840.0000, MAE: 339508515672.1564, R²: -21974661114779189488123904.0000\n",
      "\n",
      "Configurația 3: Poly Degree=None, Scaling=minmax, Select K Best=10\n",
      "MSE: 0.8649, MAE: 0.6402, R²: 0.1483\n",
      "\n",
      "Configurația 4: Poly Degree=2, Scaling=minmax, Select K Best=5\n",
      "MSE: 0.9305, MAE: 0.6421, R²: 0.0837\n",
      "\n",
      "Configurația 5: Poly Degree=3, Scaling=standard, Select K Best=None\n",
      "MSE: 8855567159274145778496345997312.0000, MAE: 139648446602440.7969, R²: -8720176566043416053393857183744.0000\n",
      "\n",
      "\n",
      "Experimente pentru RandomForestRegressor:\n",
      "Configurația 1: Poly Degree=None, Scaling=None, Select K Best=None\n",
      "MSE: 0.9327, MAE: 0.6807, R²: 0.0815\n",
      "\n",
      "Configurația 2: Poly Degree=2, Scaling=standard, Select K Best=None\n",
      "MSE: 0.9554, MAE: 0.6896, R²: 0.0592\n",
      "\n",
      "Configurația 3: Poly Degree=None, Scaling=minmax, Select K Best=10\n",
      "MSE: 0.8631, MAE: 0.6446, R²: 0.1501\n",
      "\n",
      "Configurația 4: Poly Degree=2, Scaling=minmax, Select K Best=5\n",
      "MSE: 0.9241, MAE: 0.6552, R²: 0.0901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Function to apply various transformations and evaluate models \n",
    "def experiment_with_features(model, poly_degree=None, scaling=None, select_k_best=None):\n",
    "    steps = [('preprocessor', preprocessor)]\n",
    "    \n",
    "    # Adding scaling \n",
    "    if scaling == 'standard':\n",
    "        steps.append(('scaler', StandardScaler()))\n",
    "    elif scaling == 'minmax':\n",
    "        steps.append(('scaler', MinMaxScaler()))\n",
    "    \n",
    "    # Adding polynomial features \n",
    "    if poly_degree:\n",
    "        steps.append(('poly', PolynomialFeatures(degree=poly_degree, include_bias=False)))\n",
    "    \n",
    "    # Selecting the most relevant features \n",
    "    if select_k_best:\n",
    "        steps.append(('feature_selection', SelectKBest(score_func=f_regression, k=select_k_best)))\n",
    "    \n",
    "    steps.append(('model', model))\n",
    "    \n",
    "    # Creating the pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "    # Training the model \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Making predictions \n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculating performance metrics \n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    return mse, mae, r2, pipeline\n",
    "\n",
    "# Defining models for experimentation \n",
    "models = {\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'SGDRegressor': SGDRegressor(max_iter=1000, tol=1e-3),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor()\n",
    "}\n",
    "\n",
    "# Transformation configurations for experimentation\n",
    "experiments = [\n",
    "    {'poly_degree': None, 'scaling': None, 'select_k_best': None},\n",
    "    {'poly_degree': 2, 'scaling': 'standard', 'select_k_best': None},\n",
    "    {'poly_degree': None, 'scaling': 'minmax', 'select_k_best': 10},\n",
    "    {'poly_degree': 2, 'scaling': 'minmax', 'select_k_best': 5},\n",
    "    {'poly_degree': 3, 'scaling': 'standard', 'select_k_best': None}\n",
    "]\n",
    "\n",
    "# Run experiments for each model\n",
    "experiment_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nExperimente pentru {model_name}:\")\n",
    "    model_results = []\n",
    "    \n",
    "    for i, config in enumerate(experiments):\n",
    "        mse, mae, r2, _ = experiment_with_features(model, **config)\n",
    "        print(f\"Configurația {i+1}: Poly Degree={config['poly_degree']}, Scaling={config['scaling']}, Select K Best={config['select_k_best']}\")\n",
    "        print(f\"MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\\n\")\n",
    "        \n",
    "        model_results.append({\n",
    "            'Config': config,\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'R²': r2\n",
    "        })\n",
    "    \n",
    "    experiment_results[model_name] = model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Ridge\n",
      "Test Set Metrics for Ridge:\n",
      "MSE: 0.8473721051230994, MAE: 0.6370078257812535, R²: 0.16558315905550725\n"
     ]
    }
   ],
   "source": [
    "best_model_name = results_df['MSE'].idxmin()\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "# Evaluate on test set using the best performing model\n",
    "pipeline_best = pipelines[best_model_name]\n",
    "y_pred_test = pipeline_best.predict(X_test)\n",
    "\n",
    "# Calculate metrics on test set\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Test Set Metrics for {best_model_name}:\")\n",
    "print(f\"MSE: {test_mse}, MAE: {test_mae}, R²: {test_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chiar dacă Ridge a fost cel mai performant model dintre cele testate, performanța generală nu este foarte bună. Un R² de 0.166 indică faptul că modelul nu explică bine variația din date.\n",
    "# Comparativ cu alte modele (precum DecisionTreeRegressor sau RandomForestRegressor), modelul Ridge probabil a reușit să evite suprapotrivirea, dar nu a fost suficient pentru a captura complexitatea relațiilor din date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance is not available for Ridge.\n"
     ]
    }
   ],
   "source": [
    "if best_model_name == 'Ridge' and hasattr(pipeline_best.named_steps['model'], 'feature_importances_'):\n",
    "    feature_importances = pipeline_best.named_steps['model'].feature_importances_\n",
    "    \n",
    "    # Accesăm preprocessor-ul antrenat\n",
    "    preprocessor_fitted = pipeline_best.named_steps['preprocessor']\n",
    "\n",
    "    encoded_feature_names = []\n",
    "    \n",
    "    # Căutăm OneHotEncoder în preprocessor\n",
    "    for name, transformer, cols in preprocessor_fitted.transformers_:\n",
    "        if name == 'cat':  \n",
    "            if isinstance(transformer, Pipeline):\n",
    "                for step_name, step_transformer in transformer.named_steps.items():\n",
    "                    if isinstance(step_transformer, OneHotEncoder):\n",
    "                        encoded_feature_names = step_transformer.get_feature_names_out(cols)\n",
    "                        break\n",
    "            elif isinstance(transformer, OneHotEncoder):  \n",
    "                encoded_feature_names = transformer.get_feature_names_out(cols)\n",
    "            break\n",
    "\n",
    "    # Combinăm numele caracteristicilor numerice și categoriale\n",
    "    feature_names = list(encoded_feature_names) + numerical_cols\n",
    "\n",
    "    # Verificăm dacă lungimea caracteristicilor se potrivește cu importanțele\n",
    "    if len(feature_names) != len(feature_importances):\n",
    "        raise ValueError(f\"Mismatch: {len(feature_names)} feature names vs {len(feature_importances)} importances.\")\n",
    "\n",
    "    # Creăm DataFrame pentru vizualizare\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plot Feature Importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(y=importance_df['Feature'], x=importance_df['Importance'])\n",
    "    plt.title('Feature Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Feature importance is not available for {best_model_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
