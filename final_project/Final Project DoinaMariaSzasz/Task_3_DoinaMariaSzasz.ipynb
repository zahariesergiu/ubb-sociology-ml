{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9921a2b",
   "metadata": {},
   "source": [
    "# **Final Project Task 3 - Census Modeling Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b2b8e4",
   "metadata": {},
   "source": [
    "equirements\n",
    "- Create a regression model on the Census dataset, with 'hours-per-week' target\n",
    "\n",
    "- You can use models (estmators) from sklearn, but feel free to use any library for traditional ML. \n",
    "    - Note: in sklearn, the LinearRegression estimator is based on OLS, a statistical method. Please use the SGDRegressor estimator, since this is based on gradient descent. \n",
    "    - You can use LinearRegression estimator, but only as comparison with the SGDRegressor - Optional.\n",
    "\n",
    "- Model Selection and Setup **2p**:\n",
    "    - Implement multiple models, to solve a regression problem using traditional ML: \n",
    "        - Linear Regression\n",
    "        - Decision Tree Regression\n",
    "        - Random Forest Regression - Optional\n",
    "        - Ridge Regression - Optional\n",
    "        - Lasso Regression - Optional\n",
    "    - Choose a loss (or experiment with different losses) for the model and justify the choice. *1p*\n",
    "        - MSE, MAE, RMSE, Huber Loss or others\n",
    "    - Justify model choices based on dataset characteristics and task requirements; specify model pros and cons. *1p*\n",
    "\n",
    "\n",
    "- Data Preparation\n",
    "    - Use the preprocessed datasets from Task 1.\n",
    "    - From the train set, create an extra validation set, if necesarry. So in total there will be: train, validation and test datasets.\n",
    "    - Be sure all models have their data preprocessed as needed. Some models require different, or no encoding for some features.\n",
    "\n",
    "\n",
    "- Model Training and Experimentation **10p**\n",
    "    - Establish a Baseline Model *2p*\n",
    "        - For each model type, train a simple model with default settings as a baseline.\n",
    "        - Evaluate its performance to establish a benchmark for comparison.\n",
    "    - Make plots with train, validation loss and metric on epochs (or on steps), if applicable. - Optional\n",
    "    - Feature Selection: - Optional\n",
    "        - Use insights from EDA in Task 2 to identify candidate features by analyzing patterns, relationships, and distributions.\n",
    "    - Experimentation: *8p*\n",
    "        - For each baseline model type, iteratively experiment with different combinations of features and transformations.\n",
    "        - Experiment with feature engineering techniques such as interaction terms, polynomial features, or scaling transformations.\n",
    "        - Identify the best model which have the best performance metrics on test set.\n",
    "        - You may need multiple preprocessed datasets preprocessed\n",
    "- Hyperparameter Tuning - Optional\n",
    "  - Perform hyperparameter tuning only on the best-performing model after evaluating all model types and experiments. \n",
    "  - Consider using techniques like Grid Search for exhaustive tuning, Random Search for quicker exploration, or Bayesian Optimization for an intelligent, efficient search of hyperparameters.\n",
    "  - Avoid tuning models that do not show strong baseline performance or are unlikely to outperform others based on experimentation.\n",
    "  - Ensure that hyperparameter tuning is done after completing feature selection, baseline modeling, and experimentation, ensuring that the model is stable and representative of the dataset.\n",
    "\n",
    "\n",
    "- Model Evaluation **3p**\n",
    "    - Evaluate models on the test dataset using regression metrics: *1p*\n",
    "        - Mean Absolute Error (MAE)\n",
    "        - Mean Squared Error (MSE)\n",
    "        - Root Mean Squared Error (RMSE)\n",
    "        - R² Score\n",
    "    - Choose one metric for model comparison and explain your choice *1p*\n",
    "    - Compare the results across different models. Save all experiment results  into a table. *1p*\n",
    "\n",
    "Feature Importance - Optional\n",
    "- For applicable models (e.g., Decision Tree Regression), analyze feature importance and discuss its relevance to the problem.\n",
    "\n",
    "\n",
    "\n",
    "Deliverables\n",
    "\n",
    "- Notebook code with no errors.\n",
    "- Code and results from experiments. Create a table with all experiments results, include experiment name, metrics results.\n",
    "- Explain findings, choices, results.\n",
    "- Potential areas for improvement or further exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a837c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15741586",
   "metadata": {},
   "source": [
    "1. Încărcarea datelor preprocesate (din Task 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a70fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (26029, 86) (26029,)\n",
      "Test: (6508, 86) (6508,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test  = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").squeeze()\n",
    "y_test  = pd.read_csv(\"y_test.csv\").squeeze()\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f2c86",
   "metadata": {},
   "source": [
    "2. Crearea setului de validare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ffc39e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train final: (20823, 86) (20823,)\n",
      "Validation: (5206, 86) (5206,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train final:\", X_train_final.shape, y_train_final.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8da398",
   "metadata": {},
   "source": [
    "Din setul de antrenare inițial a fost creat un set de validare, utilizat pentru evaluarea intermediară a modelelor și pentru comparația performanței acestora înainte de evaluarea finală pe setul de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f83462",
   "metadata": {},
   "source": [
    "3 Selectarea modelelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede8df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acaefe",
   "metadata": {},
   "source": [
    "Pentru problema de regresie au fost alese mai multe modele tradiționale de Machine Learning.\n",
    "\n",
    "SGDRegressor – bazat pe gradient descent, potrivit pentru seturi de date mari\n",
    "\n",
    "Linear Regression – utilizat ca model de referință (OLS)\n",
    "\n",
    "Decision Tree Regression – capabil să surprindă relații neliniare între variabile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39654bf7",
   "metadata": {},
   "source": [
    "4. Alegerea funcției Loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5e259",
   "metadata": {},
   "source": [
    "Pentru această problemă de regresie a fost aleasă funcția de pierdere **Mean Squared Error (MSE)**.\n",
    "\n",
    "MSE penalizează mai puternic erorile mari, fiind potrivită în situațiile în care dorim ca predicțiile foarte greșite să fie evitate. De asemenea, MSE este frecvent utilizată în probleme de regresie și este compatibilă cu optimizarea prin gradient descent, fiind astfel adecvată pentru modelul SGDRegressor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec95052",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model = SGDRegressor(loss=\"squared_error\", random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5acb85",
   "metadata": {},
   "source": [
    "5. Stabilirea modelelor de bază (Baseline Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33806254",
   "metadata": {},
   "source": [
    "Pentru a avea un punct de referință în evaluarea performanței modelelor, au fost antrenate modele de bază folosind setările implicite. Aceste modele permit compararea ulterioară a performanței obținute prin experimente și optimizări.\n",
    "\n",
    "Modelele de bază antrenate sunt:\n",
    "- SGDRegressor\n",
    "- Linear Regression\n",
    "- Decision Tree Regressor\n",
    "\n",
    "Evaluarea a fost realizată pe setul de validare, utilizând metrica Mean Squared Error (MSE).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e49c2",
   "metadata": {},
   "source": [
    "Import metrici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb67648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acfdd23",
   "metadata": {},
   "source": [
    "SGDRegressor – baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51243364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor - MSE (validation): 73502602679987.98\n"
     ]
    }
   ],
   "source": [
    "sgd_baseline = SGDRegressor(loss=\"squared_error\", random_state=42)\n",
    "sgd_baseline.fit(X_train_final, y_train_final)\n",
    "\n",
    "y_val_pred_sgd = sgd_baseline.predict(X_val)\n",
    "mse_sgd = mean_squared_error(y_val, y_val_pred_sgd)\n",
    "\n",
    "print(\"SGDRegressor - MSE (validation):\", mse_sgd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8525d",
   "metadata": {},
   "source": [
    "Valoarea foarte ridicată a erorii MSE obținută pentru modelul SGDRegressor indică o performanță slabă a acestuia în configurația de bază. Acest comportament este de așteptat, deoarece SGDRegressor este sensibil la diferențele de scară dintre variabile, iar datele utilizate conțin caracteristici cu valori foarte mari.\n",
    "\n",
    "Rezultatul obținut servește ca punct de referință (baseline) pentru comparațiile ulterioare. În etapele următoare, performanța modelului va fi îmbunătățită prin ajustarea parametrilor și aplicarea unor tehnici de preprocesare suplimentare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e95354c",
   "metadata": {},
   "source": [
    "Linear Regression – baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f219f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE (validation): 122.89612871893125\n"
     ]
    }
   ],
   "source": [
    "lr_baseline = LinearRegression()\n",
    "lr_baseline.fit(X_train_final, y_train_final)\n",
    "\n",
    "y_val_pred_lr = lr_baseline.predict(X_val)\n",
    "mse_lr = mean_squared_error(y_val, y_val_pred_lr)\n",
    "\n",
    "print(\"Linear Regression - MSE (validation):\", mse_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf364b14",
   "metadata": {},
   "source": [
    "Modelul Linear Regression, utilizat ca baseline, a obținut o valoare MSE de aproximativ 123 pe setul de validare, semnificativ mai mică decât cea obținută de SGDRegressor.\n",
    "\n",
    "Acest rezultat indică faptul că modelul de regresie liniară reușește să capteze relațiile principale dintre variabilele explicative și ținta hours-per-week. Performanța superioară se explică prin faptul că Linear Regression (OLS) este mai robust la diferențele de scară dintre variabile comparativ cu modelele bazate pe gradient descent.\n",
    "\n",
    "Acest model reprezintă un benchmark solid pentru etapele ulterioare de experimentare și comparație.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2979ea",
   "metadata": {},
   "source": [
    "Decision Tree Regressor – baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e6eb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - MSE (validation): 229.96928757416654\n"
     ]
    }
   ],
   "source": [
    "dt_baseline = DecisionTreeRegressor(random_state=42)\n",
    "dt_baseline.fit(X_train_final, y_train_final)\n",
    "\n",
    "y_val_pred_dt = dt_baseline.predict(X_val)\n",
    "mse_dt = mean_squared_error(y_val, y_val_pred_dt)\n",
    "\n",
    "print(\"Decision Tree - MSE (validation):\", mse_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a5546",
   "metadata": {},
   "source": [
    "Modelul Decision Tree Regressor a obținut un MSE de aproximativ 230 pe setul de validare. Deși este capabil să surprindă relații neliniare între variabile, performanța sa este mai slabă comparativ cu modelul de regresie liniară.\n",
    "\n",
    "Această diferență sugerează că, în configurația implicită, arborele de decizie tinde să supraînvețe datele de antrenare, ceea ce afectează capacitatea de generalizare. Cu toate acestea, Decision Tree rămâne un model relevant pentru etapele ulterioare de experimentare, unde pot fi aplicate tehnici de regularizare sau limitare a complexității.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c761c5",
   "metadata": {},
   "source": [
    "6. Tabel cu rezultatele baseline (Validation) + alegerea modelului câștigător"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46801ec1",
   "metadata": {},
   "source": [
    "În această secțiune compar performanța modelelor de bază antrenate (SGDRegressor, Linear Regression, Decision Tree) folosind setul de validare. Scopul este să aleg modelul / modelele care merită îmbunătățite în etapa de experimentare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acc40ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression (baseline)</td>\n",
       "      <td>1.228961e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree (baseline)</td>\n",
       "      <td>2.299693e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDRegressor (baseline)</td>\n",
       "      <td>7.350260e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model       MSE_val\n",
       "1  Linear Regression (baseline)  1.228961e+02\n",
       "2      Decision Tree (baseline)  2.299693e+02\n",
       "0       SGDRegressor (baseline)  7.350260e+13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results = pd.DataFrame({\n",
    "    \"Model\": [\"SGDRegressor (baseline)\", \"Linear Regression (baseline)\", \"Decision Tree (baseline)\"],\n",
    "    \"MSE_val\": [mse_sgd, mse_lr, mse_dt]\n",
    "}).sort_values(\"MSE_val\")\n",
    "\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9568a",
   "metadata": {},
   "source": [
    "Tabelul de mai sus prezintă performanța modelelor de bază evaluate pe setul de validare, folosind Mean Squared Error (MSE) ca metrică.\n",
    "\n",
    "- **Linear Regression (baseline)** obține cel mai mic MSE (~123), indicând cea mai bună performanță dintre modelele testate. Acest rezultat sugerează că relația dintre variabilele explicative și numărul de ore lucrate pe săptămână este în mare parte liniară, iar datele preprocesate sunt bine adaptate acestui tip de model.\n",
    "\n",
    "- **Decision Tree (baseline)** are un MSE mai mare (~230), ceea ce indică o capacitate mai slabă de generalizare în configurația de bază. Fără limitarea complexității, arborele tinde să supraînvețe datele de antrenare.\n",
    "\n",
    "- **SGDRegressor (baseline)** înregistrează un MSE extrem de mare, ceea ce indică instabilitate și o sensibilitate ridicată la setările implicite ale modelului. Acest rezultat sugerează necesitatea unui tuning atent al hiperparametrilor sau faptul că acest model nu este optim în forma sa de bază pentru acest set de date.\n",
    "\n",
    "Pe baza acestor rezultate, **Linear Regression (baseline)** este ales ca model de referință pentru etapele următoare de experimentare și evaluare finală."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257736e4",
   "metadata": {},
   "source": [
    "7. Experimentation – îmbunătățirea modelelor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfac481",
   "metadata": {},
   "source": [
    "7.1 Experiment 1 – SGDRegressor (tuning simplu)\n",
    "\n",
    "Modelul SGDRegressor este sensibil la setările de învățare (learning rate) și regularizare. În acest experiment modific parametri simpli (alpha și learning_rate) pentru a obține rezultate mai stabile decât baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7e6844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor EXP1 - MSE (validation): 73502602679987.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sgd_exp1 = SGDRegressor(\n",
    "    loss=\"squared_error\",\n",
    "    alpha=0.0001,\n",
    "    learning_rate=\"invscaling\",\n",
    "    eta0=0.01,\n",
    "    max_iter=5000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sgd_exp1.fit(X_train_final, y_train_final)\n",
    "pred_val_sgd_exp1 = sgd_exp1.predict(X_val)\n",
    "mse_sgd_exp1 = mean_squared_error(y_val, pred_val_sgd_exp1)\n",
    "\n",
    "print(\"SGDRegressor EXP1 - MSE (validation):\", mse_sgd_exp1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1790e0",
   "metadata": {},
   "source": [
    "În urma ajustării hiperparametrilor (learning rate și regularizare), performanța modelului SGDRegressor a rămas foarte slabă, cu un MSE extrem de ridicat pe setul de validare.\n",
    "\n",
    "Acest rezultat indică faptul că, chiar și după un tuning simplu, modelul SGDRegressor nu reușește să învețe o relație stabilă între variabilele explicative și ținta hours-per-week. Modelul este probabil foarte sensibil la scară și la distribuția datelor, sau necesită un tuning mult mai complex.\n",
    "\n",
    "Prin comparație cu Linear Regression, care a obținut un MSE mult mai mic, SGDRegressor se dovedește mai puțin potrivit pentru acest set de date în forma actuală.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf8e024",
   "metadata": {},
   "source": [
    "7.2 Experiment 2 – Decision Tree „control overfitting”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90bfa349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree EXP1 - MSE (validation): 118.65327335491804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "dt_exp1 = DecisionTreeRegressor(\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_exp1.fit(X_train_final, y_train_final)\n",
    "\n",
    "pred_val_dt_exp1 = dt_exp1.predict(X_val)\n",
    "mse_dt_exp1 = mean_squared_error(y_val, pred_val_dt_exp1)\n",
    "\n",
    "print(\"Decision Tree EXP1 - MSE (validation):\", mse_dt_exp1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c6e063",
   "metadata": {},
   "source": [
    "Prin limitarea complexității arborelui (max_depth=5) și impunerea unui număr minim de observații pe frunză (min_samples_leaf=20), modelul Decision Tree a obținut o performanță semnificativ mai bună pe setul de validare comparativ cu varianta baseline.\n",
    "\n",
    "MSE-ul a scăzut de la aproximativ 230 (baseline) la ~118, ceea ce indică o generalizare mult mai bună și un control eficient al supraînvățării. Acest rezultat sugerează că relațiile neliniare dintre variabile pot fi capturate eficient de un arbore de decizie, atunci când complexitatea acestuia este atent controlată.\n",
    "\n",
    "În acest moment, Decision Tree EXP1 reprezintă cel mai performant model pe setul de validare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b3279",
   "metadata": {},
   "source": [
    "7.3 Experiment 3 – Ridge Regression\n",
    "\n",
    "Ridge Regression este o extensie a regresiei liniare care adaugă regularizare (L2) pentru a reduce multicoliniaritatea și a îmbunătăți generalizarea. Testez un model Ridge cu un parametru alpha simplu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06fac603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge EXP1 - MSE (validation): 122.8960602943541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_exp1 = Ridge(alpha=1.0, random_state=42)\n",
    "ridge_exp1.fit(X_train_final, y_train_final)\n",
    "pred_val_ridge = ridge_exp1.predict(X_val)\n",
    "mse_ridge = mean_squared_error(y_val, pred_val_ridge)\n",
    "\n",
    "print(\"Ridge EXP1 - MSE (validation):\", mse_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e0216",
   "metadata": {},
   "source": [
    "Modelul Ridge Regression, care adaugă regularizare L2 peste regresia liniară, a obținut un MSE pe setul de validare foarte apropiat de cel al regresiei liniare simple.\n",
    "\n",
    "Acest rezultat sugerează că, în acest caz, regularizarea nu aduce un câștig semnificativ de performanță, probabil deoarece datele au fost deja bine preprocesate (scalare și encoding) în Task 1, iar multicoliniaritatea nu afectează major modelul.\n",
    "\n",
    "Comparativ cu Decision Tree EXP1, Ridge Regression prezintă o performanță inferioară pe setul de validare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf1e80",
   "metadata": {},
   "source": [
    "8. Tabel final cu toate experimentele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "419ca0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT EXP1 (max_depth=5, leaf=20)</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.186533e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge EXP1 (alpha=1.0)</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.228961e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear baseline</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>1.228961e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT baseline</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>2.299693e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD EXP1 (alpha+learning_rate)</td>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>7.350260e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD baseline</td>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>7.350260e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Experiment             Model       MSE_val\n",
       "4  DT EXP1 (max_depth=5, leaf=20)      DecisionTree  1.186533e+02\n",
       "5          Ridge EXP1 (alpha=1.0)             Ridge  1.228961e+02\n",
       "1                 Linear baseline  LinearRegression  1.228961e+02\n",
       "2                     DT baseline      DecisionTree  2.299693e+02\n",
       "3  SGD EXP1 (alpha+learning_rate)      SGDRegressor  7.350260e+13\n",
       "0                    SGD baseline      SGDRegressor  7.350260e+13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experiments_val = pd.DataFrame([\n",
    "    {\"Experiment\": \"SGD baseline\", \"Model\": \"SGDRegressor\", \"MSE_val\": mse_sgd},\n",
    "    {\"Experiment\": \"Linear baseline\", \"Model\": \"LinearRegression\", \"MSE_val\": mse_lr},\n",
    "    {\"Experiment\": \"DT baseline\", \"Model\": \"DecisionTree\", \"MSE_val\": mse_dt},\n",
    "\n",
    "    {\"Experiment\": \"SGD EXP1 (alpha+learning_rate)\", \"Model\": \"SGDRegressor\", \"MSE_val\": mse_sgd_exp1},\n",
    "    {\"Experiment\": \"DT EXP1 (max_depth=5, leaf=20)\", \"Model\": \"DecisionTree\", \"MSE_val\": mse_dt_exp1},\n",
    "    {\"Experiment\": \"Ridge EXP1 (alpha=1.0)\", \"Model\": \"Ridge\", \"MSE_val\": mse_ridge},\n",
    "]).sort_values(\"MSE_val\")\n",
    "\n",
    "experiments_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27363d",
   "metadata": {},
   "source": [
    "Pe baza tabelului comparativ al experimentelor, se observă că modelul\n",
    "Decision Tree Regression – EXP1 (max_depth=5, min_samples_leaf=20)\n",
    "obține cea mai mică valoare a MSE pe setul de validare.\n",
    "\n",
    "Limitarea adâncimii arborelui și impunerea unui număr minim de observații\n",
    "în frunze a redus semnificativ overfitting-ul comparativ cu modelul\n",
    "Decision Tree baseline.\n",
    "\n",
    "Modelele liniare (Linear Regression și Ridge Regression) au obținut\n",
    "performanțe similare, dar inferioare față de Decision Tree EXP1,\n",
    "indicând existența unor relații neliniare în date.\n",
    "\n",
    "SGDRegressor a avut performanțe slabe și instabile, sugerând o sensibilitate\n",
    "ridicată la hiperparametri și o potrivire mai slabă pentru acest set de date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9dafba",
   "metadata": {},
   "source": [
    "9. Evaluarea finală pe setul de test (Decision Tree EXP1)\n",
    "\n",
    "\n",
    "modelul câștigător este:\n",
    "Decision Tree Regression – EXP1 (max_depth=5, min_samples_leaf=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25437e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree EXP1 - TEST RESULTS\n",
      "MAE : 7.492817858254308\n",
      "MSE : 121.00765722844356\n",
      "RMSE: 11.000348050332024\n",
      "R2  : 0.2088900758646547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Predictii pe setul de test\n",
    "y_test_pred = dt_exp1.predict(X_test)\n",
    "\n",
    "# Metrici\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Decision Tree EXP1 - TEST RESULTS\")\n",
    "print(\"MAE :\", mae_test)\n",
    "print(\"MSE :\", mse_test)\n",
    "print(\"RMSE:\", rmse_test)\n",
    "print(\"R2  :\", r2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae64061a",
   "metadata": {},
   "source": [
    "Modelul Decision Tree Regression – EXP1 a fost evaluat pe setul de test folosind mai multe metrici de regresie.\n",
    "\n",
    "- **Mean Absolute Error (MAE ≈ 7.5)** indică faptul că, în medie, predicțiile modelului diferă cu aproximativ 7–8 ore față de valorile reale ale variabilei *hours-per-week*. Această eroare este rezonabilă, având în vedere variabilitatea mare a orelor lucrate.\n",
    "\n",
    "- **Mean Squared Error (MSE ≈ 121)** penalizează mai puternic erorile mari și confirmă faptul că modelul nu produce predicții extrem de eronate.\n",
    "\n",
    "- **Root Mean Squared Error (RMSE ≈ 11)** este ușor de interpretat deoarece se află în aceeași unitate ca variabila țintă și indică o abatere medie de aproximativ 11 ore.\n",
    "\n",
    "- **R² Score ≈ 0.21** arată că modelul explică aproximativ 21% din variația numărului de ore lucrate pe săptămână. Deși valoarea nu este foarte mare, aceasta este acceptabilă pentru un set de date socio-economic complex, unde relațiile dintre variabile sunt influențate de factori greu de modelat.\n",
    "\n",
    "În concluzie, modelul Decision Tree EXP1 generalizează rezonabil pe date nevăzute și oferă un compromis bun între bias și varianță, fiind potrivit ca model final în acest proiect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96601ed1",
   "metadata": {},
   "source": [
    "10. Concluzii finale și direcții de îmbunătățire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6327981f",
   "metadata": {},
   "source": [
    "Alegerea metricii de comparație:\n",
    "\n",
    "Pentru comparația modelelor a fost utilizată Mean Squared Error (MSE),\n",
    "deoarece penalizează mai puternic erorile mari și este o metrică standard\n",
    "în problemele de regresie.\n",
    "\n",
    "MSE este potrivită în acest context deoarece diferențele mari între\n",
    "numărul real de ore lucrate și predicții sunt nedorite.\n",
    "\n",
    "Concluzie:\n",
    "\n",
    "Cel mai performant model pentru predicția variabilei hours-per-week\n",
    "a fost Decision Tree Regression – EXP1, care a obținut cele mai bune\n",
    "rezultate atât pe setul de validare, cât și pe setul de test.\n",
    "\n",
    "Modelul reușește să surprindă relații neliniare dintre variabilele\n",
    "socio-demografice și numărul de ore lucrate, menținând totodată\n",
    "o bună capacitate de generalizare.\n",
    "\n",
    "Limitări și direcții viitoare:\n",
    "\n",
    "Valoarea relativ scăzută a scorului R² indică faptul că o parte\n",
    "semnificativă din variabilitatea lui hours-per-week nu este explicată\n",
    "doar de variabilele disponibile.\n",
    "\n",
    "Îmbunătățiri viitoare pot include:\n",
    "- adăugarea de noi variabile relevante,\n",
    "- feature engineering suplimentar,\n",
    "- utilizarea Random Forest sau Gradient Boosting,\n",
    "- tuning mai avansat al hiperparametrilor.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
