{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydHb_ZL5yy6f"
      },
      "source": [
        "# **Final Project Task 3 - Census Modeling Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnzXS8Oo9jwY"
      },
      "source": [
        "Requirements\n",
        "- Create a regression model on the Census dataset, with 'hours-per-week' target\n",
        "\n",
        "- You can use models (estmators) from sklearn, but feel free to use any library for traditional ML. \n",
        "    - Note: in sklearn, the LinearRegression estimator is based on OLS, a statistical method. Please use the SGDRegressor estimator, since this is based on gradient descent. \n",
        "    - You can use LinearRegression estimator, but only as comparison with the SGDRegressor - Optional.\n",
        "\n",
        "- Model Selection and Setup **2p**:\n",
        "    - Implement multiple models, to solve a regression problem using traditional ML: \n",
        "        - Linear Regression\n",
        "        - Decision Tree Regression\n",
        "        - Random Forest Regression - Optional\n",
        "        - Ridge Regression - Optional\n",
        "        - Lasso Regression - Optional\n",
        "    - Choose a loss (or experiment with different losses) for the model and justify the choice. *1p*\n",
        "        - MSE, MAE, RMSE, Huber Loss or others\n",
        "    - Justify model choices based on dataset characteristics and task requirements; specify model pros and cons. *1p*\n",
        "\n",
        "\n",
        "- Data Preparation\n",
        "    - Use the preprocessed datasets from Task 1.\n",
        "    - From the train set, create an extra validation set, if necesarry. So in total there will be: train, validation and test datasets.\n",
        "    - Be sure all models have their data preprocessed as needed. Some models require different, or no encoding for some features.\n",
        "\n",
        "\n",
        "- Model Training and Experimentation **10p**\n",
        "    - Establish a Baseline Model *2p*\n",
        "        - For each model type, train a simple model with default settings as a baseline.\n",
        "        - Evaluate its performance to establish a benchmark for comparison.\n",
        "    - Make plots with train, validation loss and metric on epochs (or on steps), if applicable. - Optional\n",
        "    - Feature Selection: - Optional\n",
        "        - Use insights from EDA in Task 2 to identify candidate features by analyzing patterns, relationships, and distributions.\n",
        "    - Experimentation: *8p*\n",
        "        - For each baseline model type, iteratively experiment with different combinations of features and transformations.\n",
        "        - Experiment with feature engineering techniques such as interaction terms, polynomial features, or scaling transformations.\n",
        "        - Identify the best model which have the best performance metrics on test set.\n",
        "        - You may need multiple preprocessed datasets preprocessed\n",
        "- Hyperparameter Tuning - Optional\n",
        "  - Perform hyperparameter tuning only on the best-performing model after evaluating all model types and experiments. \n",
        "  - Consider using techniques like Grid Search for exhaustive tuning, Random Search for quicker exploration, or Bayesian Optimization for an intelligent, efficient search of hyperparameters.\n",
        "  - Avoid tuning models that do not show strong baseline performance or are unlikely to outperform others based on experimentation.\n",
        "  - Ensure that hyperparameter tuning is done after completing feature selection, baseline modeling, and experimentation, ensuring that the model is stable and representative of the dataset.\n",
        "\n",
        "\n",
        "- Model Evaluation **3p**\n",
        "    - Evaluate models on the test dataset using regression metrics: *1p*\n",
        "        - Mean Absolute Error (MAE)\n",
        "        - Mean Squared Error (MSE)\n",
        "        - Root Mean Squared Error (RMSE)\n",
        "        - R² Score\n",
        "    - Choose one metric for model comparison and explain your choice *1p*\n",
        "    - Compare the results across different models. Save all experiment results  into a table. *1p*\n",
        "\n",
        "Feature Importance - Optional\n",
        "- For applicable models (e.g., Decision Tree Regression), analyze feature importance and discuss its relevance to the problem.\n",
        "\n",
        "\n",
        "\n",
        "Deliverables\n",
        "\n",
        "- Notebook code with no errors.\n",
        "- Code and results from experiments. Create a table with all experiments results, include experiment name, metrics results.\n",
        "- Explain findings, choices, results.\n",
        "- Potential areas for improvement or further exploration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xifylnglyn2W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "CzWyJfHkyn-8",
        "outputId": "633344dd-56a2-44a7-a237-a26873898c80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23965</th>\n",
              "      <td>36</td>\n",
              "      <td>Private</td>\n",
              "      <td>126675</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1977</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26151</th>\n",
              "      <td>54</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>173050</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14530</th>\n",
              "      <td>48</td>\n",
              "      <td>Private</td>\n",
              "      <td>169324</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28969</th>\n",
              "      <td>60</td>\n",
              "      <td>Private</td>\n",
              "      <td>252413</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Other</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>49</td>\n",
              "      <td>Private</td>\n",
              "      <td>160187</td>\n",
              "      <td>9th</td>\n",
              "      <td>5</td>\n",
              "      <td>Married-spouse-absent</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>Jamaica</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28057</th>\n",
              "      <td>35</td>\n",
              "      <td>Private</td>\n",
              "      <td>341102</td>\n",
              "      <td>9th</td>\n",
              "      <td>5</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14023</th>\n",
              "      <td>23</td>\n",
              "      <td>Private</td>\n",
              "      <td>376416</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23009</th>\n",
              "      <td>31</td>\n",
              "      <td>?</td>\n",
              "      <td>283531</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>?</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31396</th>\n",
              "      <td>23</td>\n",
              "      <td>Private</td>\n",
              "      <td>118023</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>?</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27397</th>\n",
              "      <td>32</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>114733</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       age  workclass  fnlwgt     education  education-num  \\\n",
              "23965   36    Private  126675       Masters             14   \n",
              "26151   54  Local-gov  173050       Masters             14   \n",
              "14530   48    Private  169324       HS-grad              9   \n",
              "28969   60    Private  252413  Some-college             10   \n",
              "6       49    Private  160187           9th              5   \n",
              "28057   35    Private  341102           9th              5   \n",
              "14023   23    Private  376416     Bachelors             13   \n",
              "23009   31          ?  283531       HS-grad              9   \n",
              "31396   23    Private  118023  Some-college             10   \n",
              "27397   32  Local-gov  114733     Bachelors             13   \n",
              "\n",
              "              marital-status         occupation   relationship   race     sex  \\\n",
              "23965     Married-civ-spouse     Prof-specialty        Husband  White    Male   \n",
              "26151     Married-civ-spouse     Prof-specialty        Husband  White    Male   \n",
              "14530          Never-married      Other-service      Unmarried  Black  Female   \n",
              "28969     Married-civ-spouse       Craft-repair        Husband  Other    Male   \n",
              "6      Married-spouse-absent      Other-service  Not-in-family  Black  Female   \n",
              "28057          Never-married  Handlers-cleaners  Not-in-family  Black    Male   \n",
              "14023          Never-married       Adm-clerical  Not-in-family  White    Male   \n",
              "23009               Divorced                  ?      Unmarried  Black  Female   \n",
              "31396          Never-married    Exec-managerial  Not-in-family  White    Male   \n",
              "27397               Divorced     Prof-specialty      Unmarried  White  Female   \n",
              "\n",
              "       capital-gain  capital-loss  hours-per-week native-country income  \n",
              "23965             0          1977              50  United-States   >50K  \n",
              "26151          7688             0              40  United-States   >50K  \n",
              "14530             0             0              32          Haiti  <=50K  \n",
              "28969             0             0              32  United-States   >50K  \n",
              "6                 0             0              16        Jamaica  <=50K  \n",
              "28057             0             0              40  United-States  <=50K  \n",
              "14023             0             0              40  United-States  <=50K  \n",
              "23009             0             0              20  United-States  <=50K  \n",
              "31396             0             0              45              ?  <=50K  \n",
              "27397             0             0              35  United-States  <=50K  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
        "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
        "    \"hours-per-week\", \"native-country\", \"income\"\n",
        "]\n",
        "\n",
        "data = pd.read_csv(data_url, header=None, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
        "data.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3 – Modelare de regresie (hours-per-week)\n",
        "\n",
        "Obiectiv: construirea și compararea mai multor modele de regresie pentru a prezice\n",
        "hours-per-week (ore lucrate/săptămână), folosind datele preprocesate din Task 1.\n",
        "Modelele vor fi evaluate pe setul de test folosind MAE, MSE, RMSE și R²."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((20823, 93), (5206, 93), (6508, 93))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# 1) Încărcare date preprocesate din Task 1 (NU raw adult.data)\n",
        "train_df = pd.read_csv(\"preprocessed_census_train.csv\")\n",
        "test_df  = pd.read_csv(\"preprocessed_census_test.csv\")\n",
        "\n",
        "TARGET = \"target_hours\"\n",
        "\n",
        "X_train_full = train_df.drop(columns=[TARGET])\n",
        "y_train_full = train_df[TARGET]\n",
        "\n",
        "X_test = test_df.drop(columns=[TARGET])\n",
        "y_test = test_df[TARGET]\n",
        "\n",
        "# 2) Split suplimentar train -> train/validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_regression(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
        "\n",
        "results = []  # aici salvăm toate experimentele\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alegerea metricii pentru comparația modelelor\n",
        "\n",
        "Pentru comparație principală folosesc RMSE, deoarece penalizează mai puternic erorile\n",
        "mari și este exprimată în aceleași unități ca variabila țintă (ore/săptămână).\n",
        "MAE este mai robust la outlieri, iar R² oferă o interpretare a proporției de variație\n",
        "explicate, însă RMSE este utilă pentru a surprinde impactul predicțiilor foarte greșite.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "sgd_baseline = SGDRegressor(random_state=42)\n",
        "sgd_baseline.fit(X_train, y_train)\n",
        "\n",
        "pred_val = sgd_baseline.predict(X_val)\n",
        "pred_test = sgd_baseline.predict(X_test)\n",
        "\n",
        "results.append({\n",
        "    \"Experiment\": \"SGDRegressor_baseline\",\n",
        "    **{f\"VAL_{k}\": v for k, v in eval_regression(y_val, pred_val).items()},\n",
        "    **{f\"TEST_{k}\": v for k, v in eval_regression(y_test, pred_test).items()},\n",
        "    \"Notes\": \"SGD default (GD-based), baseline\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "pred_val = lr.predict(X_val)\n",
        "pred_test = lr.predict(X_test)\n",
        "\n",
        "results.append({\n",
        "    \"Experiment\": \"LinearRegression_baseline\",\n",
        "    **{f\"VAL_{k}\": v for k, v in eval_regression(y_val, pred_val).items()},\n",
        "    **{f\"TEST_{k}\": v for k, v in eval_regression(y_test, pred_test).items()},\n",
        "    \"Notes\": \"OLS baseline, comparison only\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "pred_val = dt.predict(X_val)\n",
        "pred_test = dt.predict(X_test)\n",
        "\n",
        "results.append({\n",
        "    \"Experiment\": \"DecisionTree_baseline\",\n",
        "    **{f\"VAL_{k}\": v for k, v in eval_regression(y_val, pred_val).items()},\n",
        "    **{f\"TEST_{k}\": v for k, v in eval_regression(y_test, pred_test).items()},\n",
        "    \"Notes\": \"Tree baseline (no linearity assumption)\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42, n_estimators=200, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "pred_val = rf.predict(X_val)\n",
        "pred_test = rf.predict(X_test)\n",
        "\n",
        "results.append({\n",
        "    \"Experiment\": \"RandomForest_baseline\",\n",
        "    **{f\"VAL_{k}\": v for k, v in eval_regression(y_val, pred_val).items()},\n",
        "    **{f\"TEST_{k}\": v for k, v in eval_regression(y_test, pred_test).items()},\n",
        "    \"Notes\": \"RF baseline (non-linear, robust)\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "ridge = Ridge(alpha=1.0, random_state=42)\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "results.append({\n",
        "    \"Experiment\": \"Ridge_alpha1\",\n",
        "    **{f\"VAL_{k}\": v for k, v in eval_regression(y_val, ridge.predict(X_val)).items()},\n",
        "    **{f\"TEST_{k}\": v for k, v in eval_regression(y_test, ridge.predict(X_test)).items()},\n",
        "    \"Notes\": \"Regularizare L2 (reduce overfitting)\"\n",
        "})\n",
        "\n",
        "lasso = Lasso(alpha=0.001, random_state=42, max_iter=10000)\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "results.append({\n",
        "    \"Experiment\": \"Lasso_alpha0.001\",\n",
        "    **{f\"VAL_{k}\": v for k, v in eval_regression(y_val, lasso.predict(X_val)).items()},\n",
        "    **{f\"TEST_{k}\": v for k, v in eval_regression(y_test, lasso.predict(X_test)).items()},\n",
        "    \"Notes\": \"Regularizare L1 (feature selection implicit)\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "sgd_huber = SGDRegressor(\n",
        "    loss=\"huber\",        # mai robust la outlieri decât squared_error\n",
        "    alpha=1e-4,          # regularizare\n",
        "    max_iter=2000,\n",
        "    tol=1e-3,\n",
        "    random_state=42\n",
        ")\n",
        "sgd_huber.fit(X_train, y_train)\n",
        "\n",
        "results.append({\n",
        "    \"Experiment\": \"SGD_huber_alpha1e-4\",\n",
        "    **{f\"VAL_{k}\": v for k, v in eval_regression(y_val, sgd_huber.predict(X_val)).items()},\n",
        "    **{f\"TEST_{k}\": v for k, v in eval_regression(y_test, sgd_huber.predict(X_test)).items()},\n",
        "    \"Notes\": \"SGD with Huber loss (robust) + L2\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_tuned = DecisionTreeRegressor(\n",
        "    random_state=42,\n",
        "    max_depth=12,\n",
        "    min_samples_leaf=10\n",
        ")\n",
        "dt_tuned.fit(X_train, y_train)\n",
        "\n",
        "results.append({\n",
        "    \"Experiment\": \"DecisionTree_depth12_leaf10\",\n",
        "    **{f\"VAL_{k}\": v for k, v in eval_regression(y_val, dt_tuned.predict(X_val)).items()},\n",
        "    **{f\"TEST_{k}\": v for k, v in eval_regression(y_test, dt_tuned.predict(X_test)).items()},\n",
        "    \"Notes\": \"Tree with constraints to reduce overfitting\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_tuned = RandomForestRegressor(\n",
        "    random_state=42,\n",
        "    n_estimators=400,\n",
        "    max_depth=18,\n",
        "    min_samples_leaf=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_tuned.fit(X_train, y_train)\n",
        "\n",
        "results.append({\n",
        "    \"Experiment\": \"RandomForest_400_depth18_leaf5\",\n",
        "    **{f\"VAL_{k}\": v for k, v in eval_regression(y_val, rf_tuned.predict(X_val)).items()},\n",
        "    **{f\"TEST_{k}\": v for k, v in eval_regression(y_test, rf_tuned.predict(X_test)).items()},\n",
        "    \"Notes\": \"RF tuned for better generalization\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Experiment</th>\n",
              "      <th>VAL_MAE</th>\n",
              "      <th>VAL_MSE</th>\n",
              "      <th>VAL_RMSE</th>\n",
              "      <th>VAL_R2</th>\n",
              "      <th>TEST_MAE</th>\n",
              "      <th>TEST_MSE</th>\n",
              "      <th>TEST_RMSE</th>\n",
              "      <th>TEST_R2</th>\n",
              "      <th>Notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RandomForest_400_depth18_leaf5</td>\n",
              "      <td>7.265521e+00</td>\n",
              "      <td>1.125991e+02</td>\n",
              "      <td>1.061127e+01</td>\n",
              "      <td>2.501085e-01</td>\n",
              "      <td>7.265081e+00</td>\n",
              "      <td>1.133320e+02</td>\n",
              "      <td>1.064575e+01</td>\n",
              "      <td>2.590711e-01</td>\n",
              "      <td>RF tuned for better generalization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DecisionTree_depth12_leaf10</td>\n",
              "      <td>7.569380e+00</td>\n",
              "      <td>1.199367e+02</td>\n",
              "      <td>1.095156e+01</td>\n",
              "      <td>2.012409e-01</td>\n",
              "      <td>7.569996e+00</td>\n",
              "      <td>1.218900e+02</td>\n",
              "      <td>1.104038e+01</td>\n",
              "      <td>2.031213e-01</td>\n",
              "      <td>Tree with constraints to reduce overfitting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForest_baseline</td>\n",
              "      <td>7.636464e+00</td>\n",
              "      <td>1.205139e+02</td>\n",
              "      <td>1.097788e+01</td>\n",
              "      <td>1.973969e-01</td>\n",
              "      <td>7.677958e+00</td>\n",
              "      <td>1.221516e+02</td>\n",
              "      <td>1.105222e+01</td>\n",
              "      <td>2.014115e-01</td>\n",
              "      <td>RF baseline (non-linear, robust)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Lasso_alpha0.001</td>\n",
              "      <td>7.768972e+00</td>\n",
              "      <td>1.246357e+02</td>\n",
              "      <td>1.116403e+01</td>\n",
              "      <td>1.699467e-01</td>\n",
              "      <td>7.804766e+00</td>\n",
              "      <td>1.258200e+02</td>\n",
              "      <td>1.121695e+01</td>\n",
              "      <td>1.774288e-01</td>\n",
              "      <td>Regularizare L1 (feature selection implicit)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ridge_alpha1</td>\n",
              "      <td>7.769813e+00</td>\n",
              "      <td>1.246516e+02</td>\n",
              "      <td>1.116475e+01</td>\n",
              "      <td>1.698406e-01</td>\n",
              "      <td>7.807437e+00</td>\n",
              "      <td>1.258402e+02</td>\n",
              "      <td>1.121785e+01</td>\n",
              "      <td>1.772961e-01</td>\n",
              "      <td>Regularizare L2 (reduce overfitting)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LinearRegression_baseline</td>\n",
              "      <td>7.769853e+00</td>\n",
              "      <td>1.246521e+02</td>\n",
              "      <td>1.116477e+01</td>\n",
              "      <td>1.698369e-01</td>\n",
              "      <td>7.807522e+00</td>\n",
              "      <td>1.258408e+02</td>\n",
              "      <td>1.121788e+01</td>\n",
              "      <td>1.772924e-01</td>\n",
              "      <td>OLS baseline, comparison only</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SGD_huber_alpha1e-4</td>\n",
              "      <td>7.442114e+00</td>\n",
              "      <td>1.306099e+02</td>\n",
              "      <td>1.142847e+01</td>\n",
              "      <td>1.301593e-01</td>\n",
              "      <td>7.512855e+00</td>\n",
              "      <td>1.334823e+02</td>\n",
              "      <td>1.155346e+01</td>\n",
              "      <td>1.273346e-01</td>\n",
              "      <td>SGD with Huber loss (robust) + L2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DecisionTree_baseline</td>\n",
              "      <td>1.016327e+01</td>\n",
              "      <td>2.255717e+02</td>\n",
              "      <td>1.501905e+01</td>\n",
              "      <td>-5.022714e-01</td>\n",
              "      <td>1.036978e+01</td>\n",
              "      <td>2.358883e+02</td>\n",
              "      <td>1.535865e+01</td>\n",
              "      <td>-5.421631e-01</td>\n",
              "      <td>Tree baseline (no linearity assumption)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SGDRegressor_baseline</td>\n",
              "      <td>1.279575e+08</td>\n",
              "      <td>4.610914e+16</td>\n",
              "      <td>2.147304e+08</td>\n",
              "      <td>-3.070794e+14</td>\n",
              "      <td>5.454758e+08</td>\n",
              "      <td>5.524847e+20</td>\n",
              "      <td>2.350499e+10</td>\n",
              "      <td>-3.611971e+18</td>\n",
              "      <td>SGD default (GD-based), baseline</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Experiment       VAL_MAE       VAL_MSE      VAL_RMSE  \\\n",
              "8  RandomForest_400_depth18_leaf5  7.265521e+00  1.125991e+02  1.061127e+01   \n",
              "7     DecisionTree_depth12_leaf10  7.569380e+00  1.199367e+02  1.095156e+01   \n",
              "3           RandomForest_baseline  7.636464e+00  1.205139e+02  1.097788e+01   \n",
              "5                Lasso_alpha0.001  7.768972e+00  1.246357e+02  1.116403e+01   \n",
              "4                    Ridge_alpha1  7.769813e+00  1.246516e+02  1.116475e+01   \n",
              "1       LinearRegression_baseline  7.769853e+00  1.246521e+02  1.116477e+01   \n",
              "6             SGD_huber_alpha1e-4  7.442114e+00  1.306099e+02  1.142847e+01   \n",
              "2           DecisionTree_baseline  1.016327e+01  2.255717e+02  1.501905e+01   \n",
              "0           SGDRegressor_baseline  1.279575e+08  4.610914e+16  2.147304e+08   \n",
              "\n",
              "         VAL_R2      TEST_MAE      TEST_MSE     TEST_RMSE       TEST_R2  \\\n",
              "8  2.501085e-01  7.265081e+00  1.133320e+02  1.064575e+01  2.590711e-01   \n",
              "7  2.012409e-01  7.569996e+00  1.218900e+02  1.104038e+01  2.031213e-01   \n",
              "3  1.973969e-01  7.677958e+00  1.221516e+02  1.105222e+01  2.014115e-01   \n",
              "5  1.699467e-01  7.804766e+00  1.258200e+02  1.121695e+01  1.774288e-01   \n",
              "4  1.698406e-01  7.807437e+00  1.258402e+02  1.121785e+01  1.772961e-01   \n",
              "1  1.698369e-01  7.807522e+00  1.258408e+02  1.121788e+01  1.772924e-01   \n",
              "6  1.301593e-01  7.512855e+00  1.334823e+02  1.155346e+01  1.273346e-01   \n",
              "2 -5.022714e-01  1.036978e+01  2.358883e+02  1.535865e+01 -5.421631e-01   \n",
              "0 -3.070794e+14  5.454758e+08  5.524847e+20  2.350499e+10 -3.611971e+18   \n",
              "\n",
              "                                          Notes  \n",
              "8            RF tuned for better generalization  \n",
              "7   Tree with constraints to reduce overfitting  \n",
              "3              RF baseline (non-linear, robust)  \n",
              "5  Regularizare L1 (feature selection implicit)  \n",
              "4          Regularizare L2 (reduce overfitting)  \n",
              "1                 OLS baseline, comparison only  \n",
              "6             SGD with Huber loss (robust) + L2  \n",
              "2       Tree baseline (no linearity assumption)  \n",
              "0              SGD default (GD-based), baseline  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# sortăm după metrica principală (RMSE pe setul de validare)\n",
        "results_df_sorted = results_df.sort_values(\"VAL_RMSE\", ascending=True)\n",
        "\n",
        "results_df_sorted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Experiment        RandomForest_400_depth18_leaf5\n",
              "VAL_MAE                                 7.265521\n",
              "VAL_MSE                                112.59905\n",
              "VAL_RMSE                                10.61127\n",
              "VAL_R2                                  0.250108\n",
              "TEST_MAE                                7.265081\n",
              "TEST_MSE                              113.332003\n",
              "TEST_RMSE                               10.64575\n",
              "TEST_R2                                 0.259071\n",
              "Notes         RF tuned for better generalization\n",
              "Name: 8, dtype: object"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best = results_df_sorted.iloc[0]\n",
        "best_experiment = best[\"Experiment\"]\n",
        "best\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Concluzie privind modelarea\n",
        "\n",
        "În cadrul acestui task au fost implementate și evaluate mai multe modele de regresie\n",
        "pentru estimarea numărului de ore lucrate pe săptămână (hours-per-week), utilizând\n",
        "datele preprocesate obținute în Task 1. Performanța modelelor a fost evaluată pe seturi\n",
        "distincte de antrenare, validare și test, folosind metricile MAE, MSE, RMSE și R².\n",
        "\n",
        "Rezultatele indică faptul că modelele bazate pe arbori de decizie depășesc consistent\n",
        "modelele liniare și cele bazate pe gradient descent. Dintre toate modelele testate,\n",
        "RandomForestRegressor cu parametri ajustați (400 de arbori, adâncime maximă 18 și\n",
        "minimum 5 observații per frunză) a obținut cele mai bune rezultate atât pe setul de\n",
        "validare, cât și pe setul de test. Modelul a înregistrat un RMSE de aproximativ 10.6 ore\n",
        "și un coeficient R² de aproximativ 0.26 pe setul de test, indicând o capacitate superioară\n",
        "de generalizare comparativ cu alternativele evaluate.\n",
        "\n",
        "Modelele liniare (Linear Regression, Ridge și Lasso) au prezentat performanțe similare\n",
        "între ele, însă semnificativ mai slabe decât cele ale modelelor neliniare. Acest rezultat\n",
        "sugerează că relația dintre variabilele explicative și variabila țintă este în mare parte\n",
        "neliniară și nu poate fi captată eficient printr-un model liniar simplu, chiar și în\n",
        "prezența regularizării.\n",
        "\n",
        "SGDRegressor în configurația implicită a prezentat performanțe instabile și erori foarte\n",
        "ridicate, indicând sensibilitate ridicată la scalare, outlieri și alegerea funcției de\n",
        "pierdere. Utilizarea pierderii de tip Huber a îmbunătățit stabilitatea modelului, însă\n",
        "performanța acestuia a rămas inferioară modelelor bazate pe arbori.\n",
        "\n",
        "În concluzie, RandomForestRegressor reprezintă cea mai potrivită alegere pentru această\n",
        "problemă de regresie, datorită capacității sale de a modela relații neliniare complexe,\n",
        "robusteții față de outlieri și performanței superioare observate pe date nevăzute.\n",
        "Rezultatele sugerează totodată că există limitări inerente în capacitatea predictivă\n",
        "a setului de date, fapt reflectat de valorile moderate ale coeficientului R².\n",
        "\n",
        "Direcții viitoare de îmbunătățire includ explorarea unor tehnici avansate de inginerie\n",
        "a caracteristicilor, selecția automată a variabilelor relevante, precum și utilizarea\n",
        "unor modele de tip boosting (de exemplu Gradient Boosting sau XGBoost), care ar putea\n",
        "captura mai eficient structura complexă a datelor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dacă best model e tree/rf\n",
        "if \"DecisionTree\" in best_experiment:\n",
        "    importances = pd.Series(dt_tuned.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "    importances.head(15)\n",
        "elif \"RandomForest\" in best_experiment:\n",
        "    importances = pd.Series(rf_tuned.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "    importances.head(15)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
