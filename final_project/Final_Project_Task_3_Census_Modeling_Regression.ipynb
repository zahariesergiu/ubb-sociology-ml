{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydHb_ZL5yy6f"
      },
      "source": [
        "# **Final Project Task 3 - Census Modeling Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnzXS8Oo9jwY"
      },
      "source": [
        "Requirements\n",
        "\n",
        "- You can use models (estmators) from sklearn, but feel free to use any library for traditional ML. \n",
        "    - Note: in sklearn, the LinearRegression estimator is based on OLS, a statistical method. Please use the SGDRegressor estimator, since this is based on gradient descent. \n",
        "    - You can use LinearRegression estimator, but only as comparison with the SGDRegressor - Optional.\n",
        "\n",
        "- Model Selection and Setup:\n",
        "    - Implement multiple models, to solve a regression problem using traditional ML:\n",
        "        - Linear Regression\n",
        "        - Decision Tree Regression\n",
        "        - Random Forest Regression - Optional\n",
        "        - Ridge Regression - Optional\n",
        "        - Lasso Regression - Optional\n",
        "    - Choose a loss (or experiment with different losses) for the model and justify the choice.\n",
        "        - MSE, MAE, RMSE, Huber Loss or others\n",
        "    - Justify model choices based on dataset characteristics and task requirements; specify model pros and cons.\n",
        "\n",
        "\n",
        "- Data Preparation\n",
        "    - Use the preprocessed datasets from Task 1.\n",
        "    - From the train set, create an extra validation set, if necesarry. So in total there will be: train, validation and test datasets.\n",
        "    - Be sure all models have their data preprocessed as needed. Some models require different, or no encoding for some features.\n",
        "\n",
        "\n",
        "- Model Training and Experimentation\n",
        "    - Establish a Baseline Model:\n",
        "        - For each model type, train a simple model with default settings as a baseline.\n",
        "        - Evaluate its performance to establish a benchmark for comparison.\n",
        "    - Make plots with train, validation loss and metric on epochs (or on steps), if applicable. - Optional\n",
        "    - Feature Selection:\n",
        "        - Use insights from EDA in Task 2 to identify candidate features by analyzing patterns, relationships, and distributions.\n",
        "    - Experimentation:\n",
        "        - For each baseline model type, iteratively experiment with different combinations of features and transformations.\n",
        "        - Experiment with feature engineering techniques such as interaction terms, polynomial features, or scaling transformations.\n",
        "        - Identify the best model which have the best performance metrics on test set.\n",
        "    - Hyperparameter Tuning:\n",
        "        - Perform hyperparameter tuning only on the best-performing model after evaluating all model types and experiments.\n",
        "        - Avoid tuning models that do not show strong baseline performance or are unlikely to outperform others based on experimentation.\n",
        "        - Ensure that hyperparameter tuning is done after completing feature selection, baseline modeling, and experimentation, ensuring that the model is stable and representative of the dataset.\n",
        "\n",
        "\n",
        "- Model Evaluation\n",
        "    - Evaluate models on the test dataset using regression metrics:\n",
        "        - Mean Absolute Error (MAE)\n",
        "        - Mean Squared Error (MSE)\n",
        "        - Root Mean Squared Error (RMSE)\n",
        "        - RÂ² Score\n",
        "    - Compare the results across different models. Save all experiment results into a table.\n",
        "\n",
        "Feature Importance - Optional\n",
        "- For applicable models (e.g., Decision Tree Regression), analyze feature importance and discuss its relevance to the problem.\n",
        "\n",
        "\n",
        "\n",
        "Deliverables\n",
        "\n",
        "- Notebook code with no errors.\n",
        "- Code and results from experiments. Create a table with all experiments results, include experiment name, metrics results.\n",
        "- Explain findings, choices, results.\n",
        "- Potential areas for improvement or further exploration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xifylnglyn2W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "CzWyJfHkyn-8",
        "outputId": "633344dd-56a2-44a7-a237-a26873898c80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30215</th>\n",
              "      <td>50</td>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>339905</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21079</th>\n",
              "      <td>46</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>324561</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1119</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>288020</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Japan</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>52</td>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>202452</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31712</th>\n",
              "      <td>24</td>\n",
              "      <td>Private</td>\n",
              "      <td>280960</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29651</th>\n",
              "      <td>24</td>\n",
              "      <td>Private</td>\n",
              "      <td>119156</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Transport-moving</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14555</th>\n",
              "      <td>19</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>342384</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>2129</td>\n",
              "      <td>55</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9774</th>\n",
              "      <td>34</td>\n",
              "      <td>Private</td>\n",
              "      <td>344073</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Separated</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>76</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>33213</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>?</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11522</th>\n",
              "      <td>33</td>\n",
              "      <td>Private</td>\n",
              "      <td>252168</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       age         workclass  fnlwgt     education  education-num  \\\n",
              "30215   50       Federal-gov  339905  Some-college             10   \n",
              "21079   46         Local-gov  324561       Masters             14   \n",
              "1119    53           Private  288020     Bachelors             13   \n",
              "1253    52       Federal-gov  202452       HS-grad              9   \n",
              "31712   24           Private  280960       HS-grad              9   \n",
              "29651   24           Private  119156       HS-grad              9   \n",
              "14555   19  Self-emp-not-inc  342384          11th              7   \n",
              "9774    34           Private  344073       HS-grad              9   \n",
              "5201    76  Self-emp-not-inc   33213       Masters             14   \n",
              "11522   33           Private  252168  Some-college             10   \n",
              "\n",
              "           marital-status         occupation   relationship  \\\n",
              "30215  Married-civ-spouse    Exec-managerial        Husband   \n",
              "21079  Married-civ-spouse     Prof-specialty           Wife   \n",
              "1119   Married-civ-spouse     Prof-specialty        Husband   \n",
              "1253             Divorced       Adm-clerical  Not-in-family   \n",
              "31712  Married-civ-spouse  Machine-op-inspct           Wife   \n",
              "29651       Never-married   Transport-moving      Own-child   \n",
              "14555  Married-civ-spouse       Craft-repair      Own-child   \n",
              "9774            Separated       Adm-clerical  Not-in-family   \n",
              "5201   Married-civ-spouse     Prof-specialty        Husband   \n",
              "11522       Never-married      Other-service  Not-in-family   \n",
              "\n",
              "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
              "30215               White    Male             0             0              40   \n",
              "21079               White  Female             0             0              45   \n",
              "1119   Asian-Pac-Islander    Male             0             0              40   \n",
              "1253                White  Female             0             0              43   \n",
              "31712               White  Female             0             0              24   \n",
              "29651               White    Male             0             0              50   \n",
              "14555               White    Male             0          2129              55   \n",
              "9774                White    Male             0             0              40   \n",
              "5201                White    Male             0             0              30   \n",
              "11522               Black    Male             0             0              40   \n",
              "\n",
              "      native-country income  \n",
              "30215  United-States   >50K  \n",
              "21079  United-States   >50K  \n",
              "1119           Japan  <=50K  \n",
              "1253   United-States  <=50K  \n",
              "31712  United-States  <=50K  \n",
              "29651  United-States  <=50K  \n",
              "14555  United-States  <=50K  \n",
              "9774   United-States   >50K  \n",
              "5201               ?   >50K  \n",
              "11522  United-States  <=50K  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
        "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
        "    \"hours-per-week\", \"native-country\", \"income\"\n",
        "]\n",
        "\n",
        "data = pd.read_csv(data_url, header=None, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
        "data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Data preparation\n",
        "#Load and Preprocess the data\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('Data_Cleaned.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "X = data.drop(columns=['hours-per-week'])\n",
        "y = data['hours-per-week']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Split the data into train, validation, and test sets (60% train, 20% validation, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Preprocessing pipeline for numerical and categorical features\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                MSE           MAE            RÂ²\n",
            "SGDRegressor           3.324678e+37  5.142403e+18 -2.299769e+35\n",
            "DecisionTreeRegressor  2.236030e+02  1.012160e+01 -5.467221e-01\n",
            "RandomForestRegressor  1.136168e+02  7.307988e+00  2.140823e-01\n",
            "Ridge                  1.217337e+02  7.642093e+00  1.579353e-01\n",
            "Lasso                  1.366873e+02  7.398384e+00  5.449747e-02\n"
          ]
        }
      ],
      "source": [
        "#2.Model Selection and Setup\n",
        "#We will implement multiple regression models: Linear Regression, Decision Tree Regression, Random Forest Regression, Ridge Regression and Lasso Regression. \n",
        "#We will use Mean Squared Error (MSE) as our primary loss metric because it penalizes larger errors more significantly than smaller ones.\n",
        "\n",
        "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Define a function to evaluate models\n",
        "def evaluate_model(model):\n",
        "    # Create a pipeline that includes preprocessing and model training\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                ('model', model)])\n",
        "    \n",
        "    # Fit the model on training data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict on validation set\n",
        "    y_pred_test = pipeline.predict(X_test)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_test, y_pred_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred_test)\n",
        "    r2 = r2_score(y_test, y_pred_test)\n",
        "    \n",
        "    return mse, mae, r2, pipeline\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'SGDRegressor': SGDRegressor(),\n",
        "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
        "    'RandomForestRegressor': RandomForestRegressor(),\n",
        "    'Ridge': Ridge(),\n",
        "    'Lasso': Lasso()\n",
        "}\n",
        "\n",
        "# Evaluate each model and store results\n",
        "results = {}\n",
        "pipelines = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    mse, mae, r2, pipeline = evaluate_model(model)\n",
        "    results[name] = {'MSE': mse, 'MAE': mae, 'RÂ²': r2}\n",
        "    pipelines[name] = pipeline\n",
        "\n",
        "# Convert results to DataFrame for better visualization\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#3. Model Training and Experimentation\n",
        "#Baseline Model Training\n",
        "#We will establish baseline performance by training each model with default settings and evaluating their performance.\n",
        "#Hyperparameter Tuning\n",
        "#For models that show strong baseline performance (e.g., Random Forest or Ridge), we can perform hyperparameter tuning using GridSearchCV or RandomizedSearchCV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model: RandomForestRegressor\n",
            "Test Set Metrics for RandomForestRegressor:\n",
            "MSE: 113.61677179827473, MAE: 7.307987723954878, RÂ²: 0.21408231104125985\n"
          ]
        }
      ],
      "source": [
        "#4. Model Evaluation\n",
        "#After training the models on the validation set:\n",
        "#Evaluate Models on Test Dataset: Use metrics such as MAE, MSE, RMSE (calculated from MSE), and RÂ² Score to compare model performances.\n",
        "# Evaluate on test set using the best performing model (for example: RandomForestRegressor)\n",
        "best_model_name = results_df['MSE'].idxmin()\n",
        "print(f\"Best model: {best_model_name}\")\n",
        "\n",
        "# Evaluate on test set using the best performing model\n",
        "pipeline_best = pipelines[best_model_name]\n",
        "y_pred_test = pipeline_best.predict(X_test)\n",
        "\n",
        "# Calculate metrics on test set\n",
        "test_mse = mean_squared_error(y_test, y_pred_test)\n",
        "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
        "test_r2 = r2_score(y_test, y_pred_test)\n",
        "\n",
        "print(f\"Test Set Metrics for {best_model_name}:\")\n",
        "print(f\"MSE: {test_mse}, MAE: {test_mae}, RÂ²: {test_r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pe baza caracteristicilor generale ale setului de date Èi a cerinÈelor sarcinilor, regresia aleatorie a pÄdurii este probabil cel mai bun model. EchilibreazÄ acurateÈea, robusteÈea Èi capacitatea de a gestiona diferite tipuri de caracteristici fÄrÄ a face presupuneri puternice cu privire la relaÈiile de bazÄ. Cu toate acestea, pentru a confirma acest lucru, evaluarea empiricÄ este necesarÄ prin instruirea Èi compararea modelelor folosind seturile de date de validare Èi testare Èi metricile de evaluare alese."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'sns' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Plot Feature Importance\u001b[39;00m\n\u001b[0;32m     38\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m---> 39\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mbarplot(y\u001b[38;5;241m=\u001b[39mimportance_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m], x\u001b[38;5;241m=\u001b[39mimportance_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     40\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature Importance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     41\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#5. Findings and Conclusions\n",
        "#Model Performance: Compare the performance of different models based on their evaluation metrics.\n",
        "#Feature Importance: For tree-based models like Decision Trees or Random Forests, analyze feature importance to identify which features have the most significant impact on predicting \"hours-per-week\".\n",
        "\n",
        "\n",
        "if best_model_name == 'RandomForestRegressor' and hasattr(pipeline_best.named_steps['model'], 'feature_importances_'):\n",
        "    feature_importances = pipeline_best.named_steps['model'].feature_importances_\n",
        "    \n",
        "    # AccesÄm preprocessor-ul antrenat\n",
        "    preprocessor_fitted = pipeline_best.named_steps['preprocessor']\n",
        "\n",
        "    encoded_feature_names = []\n",
        "    \n",
        "    # CÄutÄm OneHotEncoder Ã®n preprocessor\n",
        "    for name, transformer, cols in preprocessor_fitted.transformers_:\n",
        "        if name == 'cat':  \n",
        "            if isinstance(transformer, Pipeline):\n",
        "                for step_name, step_transformer in transformer.named_steps.items():\n",
        "                    if isinstance(step_transformer, OneHotEncoder):\n",
        "                        encoded_feature_names = step_transformer.get_feature_names_out(cols)\n",
        "                        break\n",
        "            elif isinstance(transformer, OneHotEncoder):  \n",
        "                encoded_feature_names = transformer.get_feature_names_out(cols)\n",
        "            break\n",
        "\n",
        "    # CombinÄm numele caracteristicilor numerice Èi categoriale\n",
        "    feature_names = list(encoded_feature_names) + numerical_cols\n",
        "\n",
        "    # VerificÄm dacÄ lungimea caracteristicilor se potriveÈte cu importanÈele\n",
        "    if len(feature_names) != len(feature_importances):\n",
        "        raise ValueError(f\"Mismatch: {len(feature_names)} feature names vs {len(feature_importances)} importances.\")\n",
        "\n",
        "    # CreÄm DataFrame pentru vizualizare\n",
        "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Plot Feature Importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(y=importance_df['Feature'], x=importance_df['Importance'])\n",
        "    plt.title('Feature Importance')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"Feature importance is not available for {best_model_name}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#6. Potential Areas for Improvement or Further Exploration\n",
        "#Feature Engineering: Explore additional feature engineering techniques such as interaction terms or polynomial features.\n",
        "#Advanced Models: Consider experimenting with more advanced regression techniques like Gradient Boosting or XGBoost.\n",
        "#Cross-Validation: Implement k-fold cross-validation to ensure robustness in model evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "my_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
