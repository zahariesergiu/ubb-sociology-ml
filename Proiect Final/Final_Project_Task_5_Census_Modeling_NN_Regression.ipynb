{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydHb_ZL5yy6f"
      },
      "source": [
        "# **Final Project Task 5 - Census Modeling NN Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnzXS8Oo9jwY"
      },
      "source": [
        "Requirements\n",
        "\n",
        "- Create a NN regression model on the Census dataset, with 'hours-per-week' target\n",
        "\n",
        "- Model Selection and Setup:\n",
        "    - Build a neural network model using a deep learning library like TensorFlow, Keras or PyTorch.\n",
        "    - Choose a loss (or experiment with different losses) for the model and justify the choice.\n",
        "        - MSE, MAE, RMSE, Huber Loss or others\n",
        "    - Justify model choices based on dataset characteristics and task requirements; specify model pros and cons.\n",
        "\n",
        "\n",
        "- Data Preparation\n",
        "    - Use the preprocessed datasets from Task 1.\n",
        "    - From the train set, create an extra validation set, if necesarry. So in total there will be: train, validation and test datasets.\n",
        "    - Be sure all models have their data preprocessed as needed. Some models require different, or no encoding for some features.\n",
        "\n",
        "\n",
        "- Model Training and Experimentation\n",
        "    - Establish a Baseline Model:\n",
        "        - Train a simple NN model with default settings as a baseline.\n",
        "        - Evaluate its performance to establish a benchmark for comparison.\n",
        "    - Make plots with train, validation loss and metric on epochs (or on steps), if applicable.\n",
        "    - Feature Selection:\n",
        "        - Neural Networks can learn feature importance automatically, so all relevant features should be included rather than manually selecting a subset.\n",
        "        - Consider using embeddings for high-cardinality categorical features instead of one-hot encoding to improve efficiency.\n",
        "    - Experimentation:\n",
        "        - Focus on preprocessing techniques rather than manually selecting feature combinations. Ensure numerical features are normalized (e.g., MinMaxScaler, StandardScaler) and categorical features are properly encoded (e.g., one-hot encoding or embeddings for high-cardinality variables).\n",
        "        - Experiment with different neural network architectures (e.g., number of layers, neurons per layer) and hyperparameters (e.g., activation functions, learning rates, dropout rates, and batch sizes).\n",
        "        - Use techniques such as early stopping and learning rate scheduling to optimize model performance and prevent overfitting.\n",
        "        - Identify the best model which have the best performance metrics on test set.\n",
        "    - Hyperparameter Tuning:\n",
        "        - Perform hyperparameter tuning only on the best-performing model after evaluating all model types and experiments.\n",
        "        - Consider using techniques like Grid Search for exhaustive tuning, Random Search for quicker exploration, or Bayesian Optimization for an intelligent, efficient search of hyperparameters.\n",
        "        - Avoid tuning models that do not show strong baseline performance or are unlikely to outperform others based on experimentation.\n",
        "        - Ensure that hyperparameter tuning is done after completing feature selection, baseline modeling, and experimentation, ensuring that the model is stable and representative of the dataset.\n",
        "\n",
        "\n",
        "- Model Evaluation\n",
        "    - Evaluate models on the test dataset using regression metrics:\n",
        "        - Mean Absolute Error (MAE)\n",
        "        - Mean Squared Error (MSE)\n",
        "        - Root Mean Squared Error (RMSE)\n",
        "        - R² Score\n",
        "    - Choose one metric for model comparison and explain your choice\n",
        "    - Compare the results across different models. Save all experiment results into a table.\n",
        "\n",
        "\n",
        "\n",
        "Deliverables\n",
        "\n",
        "- Notebook code with no errors.\n",
        "- Code and results from experiments. Create a table with all experiments results, include experiment name, metrics results.\n",
        "- Explain findings, choices, results.\n",
        "- Potential areas for improvement or further exploration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importuri + setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x24bcb903470>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xifylnglyn2W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (6508, 122)\n",
            "Test shape : (26029, 122)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education-num</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>capital_net</th>\n",
              "      <th>capital_gain_log</th>\n",
              "      <th>capital_loss_log</th>\n",
              "      <th>has_capital</th>\n",
              "      <th>is_married</th>\n",
              "      <th>...</th>\n",
              "      <th>native-country_Vietnam</th>\n",
              "      <th>native-country_Yugoslavia</th>\n",
              "      <th>income_&lt;=50K</th>\n",
              "      <th>income_&gt;50K</th>\n",
              "      <th>age_bin_25-34</th>\n",
              "      <th>age_bin_35-44</th>\n",
              "      <th>age_bin_45-59</th>\n",
              "      <th>age_bin_60+</th>\n",
              "      <th>age_bin_&lt;25</th>\n",
              "      <th>hours-per-week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.557141</td>\n",
              "      <td>-1.619320</td>\n",
              "      <td>0.355672</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.059838</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.073840</td>\n",
              "      <td>-0.596512</td>\n",
              "      <td>1.169686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.943541</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.583469</td>\n",
              "      <td>-0.935084</td>\n",
              "      <td>-0.051335</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.059838</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 122 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        age    fnlwgt  education-num  capital-gain  capital-loss  capital_net  \\\n",
              "0 -0.557141 -1.619320       0.355672           0.0           0.0          0.0   \n",
              "1 -1.073840 -0.596512       1.169686           0.0           0.0          0.0   \n",
              "2  1.583469 -0.935084      -0.051335           0.0           0.0          0.0   \n",
              "\n",
              "   capital_gain_log  capital_loss_log  has_capital  is_married  ...  \\\n",
              "0               0.0               0.0          0.0    1.059838  ...   \n",
              "1               0.0               0.0          0.0   -0.943541  ...   \n",
              "2               0.0               0.0          0.0    1.059838  ...   \n",
              "\n",
              "   native-country_Vietnam  native-country_Yugoslavia  income_<=50K  \\\n",
              "0                     0.0                        0.0           1.0   \n",
              "1                     0.0                        0.0           1.0   \n",
              "2                     0.0                        0.0           1.0   \n",
              "\n",
              "   income_>50K  age_bin_25-34  age_bin_35-44  age_bin_45-59  age_bin_60+  \\\n",
              "0          0.0            1.0            0.0            0.0          0.0   \n",
              "1          0.0            0.0            0.0            0.0          0.0   \n",
              "2          0.0            0.0            0.0            1.0          0.0   \n",
              "\n",
              "   age_bin_<25  hours-per-week  \n",
              "0          0.0              40  \n",
              "1          1.0              40  \n",
              "2          0.0              60  \n",
              "\n",
              "[3 rows x 122 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load preprocessed data from Task 1\n",
        "train_df = pd.read_csv(\"test_preprocessed.csv\")\n",
        "test_df  = pd.read_csv(\"train_preprocessed.csv\")\n",
        "    \n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape :\", test_df.shape)\n",
        "\n",
        "display(train_df.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5206, 121), (1302, 121), (26029, 121))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "TARGET = \"hours-per-week\"\n",
        "\n",
        "X_train_full = train_df.drop(columns=[TARGET]).to_numpy().astype(np.float32)\n",
        "y_train_full = train_df[TARGET].to_numpy().astype(np.float32)\n",
        "\n",
        "X_test = test_df.drop(columns=[TARGET]).to_numpy().astype(np.float32)\n",
        "y_test = test_df[TARGET].to_numpy().astype(np.float32)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observati**: În această etapă sunt importate bibliotecile necesare pentru procesarea datelor, construirea modelului de regresie și evaluarea performanței.\n",
        "\n",
        "- numpy este utilizat pentru operații numerice eficiente.\n",
        "\n",
        "- pandas este folosit pentru manipularea seturilor de date.\n",
        "\n",
        "- scikit-learn este utilizat pentru împărțirea datelor și calculul metricilor de evaluare.\n",
        "\n",
        "TensorFlow / Keras este biblioteca aleasă pentru construirea și antrenarea modelului de Neural Network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load data (preprocessed) + split train/val/test\n",
        "Variabila țintă a problemei de regresie este definită ca hours-per-week, reprezentând numărul de ore lucrate pe săptămână."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5206, 121), (1302, 121), (26029, 121))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TARGET = \"hours-per-week\"\n",
        "\n",
        "X_train_full = train_df.drop(columns=[TARGET]).to_numpy().astype(np.float32)\n",
        "y_train_full = train_df[TARGET].to_numpy().astype(np.float32)\n",
        "\n",
        "X_test = test_df.drop(columns=[TARGET]).to_numpy().astype(np.float32)\n",
        "y_test = test_df[TARGET].to_numpy().astype(np.float32)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observati**: Dimensiunile finale ale seturilor de date sunt:\n",
        "\n",
        "Train: 5206 observații × 121 features\n",
        "\n",
        "Validation: 1302 observații × 121 features\n",
        "\n",
        "Test: 26029 observații × 121 features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    TensorDataset(torch.tensor(X_train), torch.tensor(y_train).unsqueeze(1)),\n",
        "    batch_size=BATCH_SIZE, shuffle=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    TensorDataset(torch.tensor(X_val), torch.tensor(y_val).unsqueeze(1)),\n",
        "    batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    TensorDataset(torch.tensor(X_test), torch.tensor(y_test).unsqueeze(1)),\n",
        "    batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BaselineNN(\n",
              "  (net): Sequential(\n",
              "    (0): Linear(in_features=121, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class BaselineNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BaselineNN(input_dim=X_train.shape[1]).to(device)\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observatii**: A fost construit un Neural Network de bază (baseline) pentru problema de regresie, utilizat ca punct de referință pentru experimentele ulterioare.\n",
        "\n",
        "Arhitectura modelului este un Multi-Layer Perceptron (MLP) cu:\n",
        "\n",
        "- un strat de intrare corespunzător celor 121 de variabile explicative,\n",
        "\n",
        "- două straturi ascunse cu 64 și 32 neuroni,\n",
        "\n",
        "- un strat de ieșire cu un singur neuron, specific problemelor de regresie.\n",
        "\n",
        "Funcția de activare ReLU este utilizată în straturile ascunse pentru a introduce non-liniaritate și pentru a facilita o convergență mai rapidă în timpul antrenării.\n",
        "\n",
        "Stratul de ieșire nu utilizează o funcție de activare, permițând modelului să producă valori continue pentru variabila țintă (hours-per-week)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss + optimizer (Alege Huber / MSE / MAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.SmoothL1Loss()  # Huber-like\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train loop + log (train/val loss + MAE per epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | train_loss=39.8072 | val_loss=39.4039 | val_mae=39.9038\n",
            "Epoch 02 | train_loss=38.7765 | val_loss=37.4614 | val_mae=37.9613\n",
            "Epoch 03 | train_loss=35.2661 | val_loss=31.5326 | val_mae=32.0316\n",
            "Epoch 04 | train_loss=26.3349 | val_loss=18.8063 | val_mae=19.3051\n",
            "Epoch 05 | train_loss=11.7478 | val_loss=8.6075 | val_mae=9.0937\n",
            "Epoch 06 | train_loss=7.7333 | val_loss=7.5148 | val_mae=7.9873\n",
            "Epoch 07 | train_loss=6.9930 | val_loss=7.2194 | val_mae=7.6883\n",
            "Epoch 08 | train_loss=6.8638 | val_loss=7.1912 | val_mae=7.6569\n",
            "Epoch 09 | train_loss=6.8268 | val_loss=7.1754 | val_mae=7.6418\n",
            "Epoch 10 | train_loss=6.8068 | val_loss=7.1603 | val_mae=7.6261\n",
            "Epoch 11 | train_loss=6.7912 | val_loss=7.1496 | val_mae=7.6169\n",
            "Epoch 12 | train_loss=6.7765 | val_loss=7.1435 | val_mae=7.6111\n",
            "Epoch 13 | train_loss=6.7710 | val_loss=7.1416 | val_mae=7.6082\n",
            "Epoch 14 | train_loss=6.7566 | val_loss=7.1305 | val_mae=7.5982\n",
            "Epoch 15 | train_loss=6.7448 | val_loss=7.1257 | val_mae=7.5952\n",
            "Epoch 16 | train_loss=6.7345 | val_loss=7.1168 | val_mae=7.5816\n",
            "Epoch 17 | train_loss=6.7225 | val_loss=7.1153 | val_mae=7.5816\n",
            "Epoch 18 | train_loss=6.7112 | val_loss=7.1014 | val_mae=7.5685\n",
            "Epoch 19 | train_loss=6.7053 | val_loss=7.0964 | val_mae=7.5661\n",
            "Epoch 20 | train_loss=6.6917 | val_loss=7.0894 | val_mae=7.5558\n",
            "Epoch 21 | train_loss=6.6869 | val_loss=7.0944 | val_mae=7.5607\n",
            "Epoch 22 | train_loss=6.6705 | val_loss=7.0660 | val_mae=7.5325\n",
            "Epoch 23 | train_loss=6.6642 | val_loss=7.0525 | val_mae=7.5172\n",
            "Epoch 24 | train_loss=6.6529 | val_loss=7.0450 | val_mae=7.5110\n",
            "Epoch 25 | train_loss=6.6359 | val_loss=7.0346 | val_mae=7.4995\n",
            "Epoch 26 | train_loss=6.6231 | val_loss=7.0443 | val_mae=7.5144\n",
            "Epoch 27 | train_loss=6.6158 | val_loss=7.0213 | val_mae=7.4855\n",
            "Epoch 28 | train_loss=6.6037 | val_loss=7.0152 | val_mae=7.4797\n",
            "Epoch 29 | train_loss=6.5946 | val_loss=7.0173 | val_mae=7.4800\n",
            "Epoch 30 | train_loss=6.5866 | val_loss=7.0068 | val_mae=7.4703\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds, all_true = [], []\n",
        "    total_loss = 0.0\n",
        "    n = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            preds = model(xb)\n",
        "            loss = loss_fn(preds, yb)\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "            n += xb.size(0)\n",
        "\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_true.append(yb.cpu().numpy())\n",
        "\n",
        "    y_pred = np.vstack(all_preds).ravel()\n",
        "    y_true = np.vstack(all_true).ravel()\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    return total_loss / n, mae\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "train_maes, val_maes = [], []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    n = 0\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = loss_fn(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "        n += xb.size(0)\n",
        "\n",
        "    train_loss_epoch = running_loss / n\n",
        "    val_loss_epoch, val_mae_epoch = evaluate(model, val_loader)\n",
        "\n",
        "    # train MAE (calc on whole train set)\n",
        "    train_loss_eval, train_mae_epoch = evaluate(model, train_loader)\n",
        "\n",
        "    train_losses.append(train_loss_epoch)\n",
        "    val_losses.append(val_loss_epoch)\n",
        "    train_maes.append(train_mae_epoch)\n",
        "    val_maes.append(val_mae_epoch)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | train_loss={train_loss_epoch:.4f} | val_loss={val_loss_epoch:.4f} | val_mae={val_mae_epoch:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observati**: Evoluția loss-ului arată o scădere consistentă atât pe setul de train, cât și pe setul de validation, ceea ce indică faptul că modelul învață relații relevante din date.\n",
        "\n",
        "MAE pe setul de validation scade rapid în primele epoci (de la valori peste 30), apoi se stabilizează în jurul valorii de ~7.5 ore, sugerând o bună capacitate de generalizare.\n",
        "\n",
        "Diferența relativ mică dintre training loss și validation loss indică faptul că modelul nu suferă de overfitting semnificativ în configurația actuală."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ploturi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.title(\"Loss over epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"train\", \"val\"])\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_maes)\n",
        "plt.plot(val_maes)\n",
        "plt.title(\"MAE over epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.legend([\"train\", \"val\"])\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observati**: Graficele prezintă evoluția loss-ului și a Mean Absolute Error (MAE) pe parcursul epocilor, atât pentru setul de train, cât și pentru setul de validation.\n",
        "Curbele de training și validation loss urmează o evoluție similară și rămân apropiate pe parcursul antrenării.\n",
        "\n",
        "Lipsa unei divergențe între cele două curbe indică faptul că modelul nu suferă de overfitting în configurația actuală."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluare finală pe test (MAE, MSE, RMSE, R2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7.239856243133545,\n",
              " 123.05044555664062,\n",
              " np.float64(11.092810534604864),\n",
              " 0.192055344581604)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for xb, _ in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        preds = model(xb).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "\n",
        "y_pred_test = np.vstack(all_preds).ravel()\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred_test)\n",
        "mse = mean_squared_error(y_test, y_pred_test)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred_test)\n",
        "\n",
        "mae, mse, rmse, r2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observati**: \n",
        "MAE ≈ 7.24 În medie, predicțiile modelului diferă de valorile reale cu aproximativ 7.2 ore pe săptămână, ceea ce oferă o interpretare directă și intuitivă a erorii.\n",
        "\n",
        "MSE ≈ 123.05 și RMSE ≈ 11.09 Valorile RMSE mai ridicate indică existența unor erori mai mari pentru anumite observații, sugerând prezența outlierilor în date.\n",
        "\n",
        "R² ≈ 0.19 Modelul explică aproximativ 19% din variația variabilei țintă (hours-per-week), ceea ce este rezonabil având în vedere complexitatea și natura socio-demografică a datasetului Census.\n",
        "\n",
        "Modelul obține o eroare medie de aproximativ 7 ore pe săptămână pe setul de test, demonstrând o capacitate rezonabilă de generalizare, dar și potențial de îmbunătățire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experimentare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Experiment</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E1_baseline_64_32_huber</td>\n",
              "      <td>7.301157</td>\n",
              "      <td>125.892380</td>\n",
              "      <td>11.220177</td>\n",
              "      <td>0.173395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E2_128_64_huber</td>\n",
              "      <td>7.311493</td>\n",
              "      <td>124.779305</td>\n",
              "      <td>11.170466</td>\n",
              "      <td>0.180704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E3_128_64_drop02_huber</td>\n",
              "      <td>7.393404</td>\n",
              "      <td>120.288048</td>\n",
              "      <td>10.967591</td>\n",
              "      <td>0.210193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>E4_128_64_mse</td>\n",
              "      <td>7.676962</td>\n",
              "      <td>118.711754</td>\n",
              "      <td>10.895492</td>\n",
              "      <td>0.220543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Experiment       MAE         MSE       RMSE        R2\n",
              "0  E1_baseline_64_32_huber  7.301157  125.892380  11.220177  0.173395\n",
              "1          E2_128_64_huber  7.311493  124.779305  11.170466  0.180704\n",
              "2   E3_128_64_drop02_huber  7.393404  120.288048  10.967591  0.210193\n",
              "3            E4_128_64_mse  7.676962  118.711754  10.895492  0.220543"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def build_model(input_dim, hidden_units=(128, 64), dropout=0.0, activation=\"relu\"):\n",
        "    act = nn.ReLU if activation == \"relu\" else nn.Tanh\n",
        "    layers_list = []\n",
        "    prev = input_dim\n",
        "\n",
        "    for u in hidden_units:\n",
        "        layers_list.append(nn.Linear(prev, u))\n",
        "        layers_list.append(act())\n",
        "        if dropout > 0:\n",
        "            layers_list.append(nn.Dropout(dropout))\n",
        "        prev = u\n",
        "\n",
        "    layers_list.append(nn.Linear(prev, 1))\n",
        "    return nn.Sequential(*layers_list)\n",
        "\n",
        "def train_one_experiment(cfg):\n",
        "    m = build_model(X_train.shape[1], cfg[\"hidden_units\"], cfg[\"dropout\"], cfg[\"activation\"]).to(device)\n",
        "\n",
        "    # loss choice\n",
        "    if cfg[\"loss\"] == \"mse\":\n",
        "        lf = nn.MSELoss()\n",
        "    elif cfg[\"loss\"] == \"mae\":\n",
        "        lf = nn.L1Loss()\n",
        "    else:\n",
        "        lf = nn.SmoothL1Loss()  # huber\n",
        "\n",
        "    opt = torch.optim.Adam(m.parameters(), lr=cfg[\"lr\"])\n",
        "\n",
        "    # quick training (keep small for speed)\n",
        "    E = cfg[\"epochs\"]\n",
        "    for _ in range(E):\n",
        "        m.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            pred = m(xb)\n",
        "            loss = lf(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    # test preds\n",
        "    m.eval()\n",
        "    preds_all = []\n",
        "    with torch.no_grad():\n",
        "        for xb, _ in test_loader:\n",
        "            xb = xb.to(device)\n",
        "            preds_all.append(m(xb).cpu().numpy())\n",
        "    y_pred = np.vstack(preds_all).ravel()\n",
        "\n",
        "    mae_ = mean_absolute_error(y_test, y_pred)\n",
        "    mse_ = mean_squared_error(y_test, y_pred)\n",
        "    rmse_ = np.sqrt(mse_)\n",
        "    r2_ = r2_score(y_test, y_pred)\n",
        "    return mae_, mse_, rmse_, r2_\n",
        "\n",
        "configs = [\n",
        "    {\"name\":\"E1_baseline_64_32_huber\", \"hidden_units\":(64,32), \"dropout\":0.0, \"activation\":\"relu\", \"lr\":1e-3, \"loss\":\"huber\", \"epochs\":20},\n",
        "    {\"name\":\"E2_128_64_huber\",         \"hidden_units\":(128,64), \"dropout\":0.0, \"activation\":\"relu\", \"lr\":1e-3, \"loss\":\"huber\", \"epochs\":20},\n",
        "    {\"name\":\"E3_128_64_drop02_huber\",  \"hidden_units\":(128,64), \"dropout\":0.2, \"activation\":\"relu\", \"lr\":1e-3, \"loss\":\"huber\", \"epochs\":20},\n",
        "    {\"name\":\"E4_128_64_mse\",           \"hidden_units\":(128,64), \"dropout\":0.0, \"activation\":\"relu\", \"lr\":1e-3, \"loss\":\"mse\",   \"epochs\":20},\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for cfg in configs:\n",
        "    mae_, mse_, rmse_, r2_ = train_one_experiment(cfg)\n",
        "    rows.append([cfg[\"name\"], mae_, mse_, rmse_, r2_])\n",
        "\n",
        "results_df = pd.DataFrame(rows, columns=[\"Experiment\",\"MAE\",\"MSE\",\"RMSE\",\"R2\"]).sort_values(\"MAE\")\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observati**: Deși s-a utilizat codificarea cu o singură funcționalitate (one-hot encoding), straturile încorporate ar putea fi luate în considerare pentru caracteristici categorice cu cardinalitate ridicată, pentru a reduce dimensionalitatea și a îmbunătăți eficiența în lucrările viitoare."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Run</th>\n",
              "      <th>dropout</th>\n",
              "      <th>lr</th>\n",
              "      <th>loss</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>huber</td>\n",
              "      <td>7.356822</td>\n",
              "      <td>133.174011</td>\n",
              "      <td>11.540104</td>\n",
              "      <td>0.125584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>T7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>huber</td>\n",
              "      <td>7.431906</td>\n",
              "      <td>124.447693</td>\n",
              "      <td>11.155613</td>\n",
              "      <td>0.182881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.001019</td>\n",
              "      <td>huber</td>\n",
              "      <td>7.442598</td>\n",
              "      <td>120.152725</td>\n",
              "      <td>10.961420</td>\n",
              "      <td>0.211082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>T8</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.001531</td>\n",
              "      <td>huber</td>\n",
              "      <td>7.469151</td>\n",
              "      <td>120.335854</td>\n",
              "      <td>10.969770</td>\n",
              "      <td>0.209879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>huber</td>\n",
              "      <td>7.541051</td>\n",
              "      <td>137.587830</td>\n",
              "      <td>11.729784</td>\n",
              "      <td>0.096603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000662</td>\n",
              "      <td>mse</td>\n",
              "      <td>7.572160</td>\n",
              "      <td>118.633736</td>\n",
              "      <td>10.891911</td>\n",
              "      <td>0.221055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000665</td>\n",
              "      <td>mse</td>\n",
              "      <td>7.618897</td>\n",
              "      <td>118.461464</td>\n",
              "      <td>10.884000</td>\n",
              "      <td>0.222186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>T6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>mse</td>\n",
              "      <td>7.694831</td>\n",
              "      <td>131.563385</td>\n",
              "      <td>11.470108</td>\n",
              "      <td>0.136160</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Run  dropout        lr   loss       MAE         MSE       RMSE        R2\n",
              "2  T3      0.0  0.000219  huber  7.356822  133.174011  11.540104  0.125584\n",
              "6  T7      0.3  0.000277  huber  7.431906  124.447693  11.155613  0.182881\n",
              "4  T5      0.3  0.001019  huber  7.442598  120.152725  10.961420  0.211082\n",
              "7  T8      0.3  0.001531  huber  7.469151  120.335854  10.969770  0.209879\n",
              "3  T4      0.1  0.000117  huber  7.541051  137.587830  11.729784  0.096603\n",
              "1  T2      0.2  0.000662    mse  7.572160  118.633736  10.891911  0.221055\n",
              "0  T1      0.2  0.000665    mse  7.618897  118.461464  10.884000  0.222186\n",
              "5  T6      0.2  0.000195    mse  7.694831  131.563385  11.470108  0.136160"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "best_family = {\"hidden_units\": (128,64), \"activation\":\"relu\"}  # pornește de la cel mai bun din results_df\n",
        "\n",
        "tuning_rows = []\n",
        "for i in range(8):  # 8 încercări rapide\n",
        "    cfg = {\n",
        "        \"name\": f\"T{i+1}\",\n",
        "        \"hidden_units\": best_family[\"hidden_units\"],\n",
        "        \"dropout\": random.choice([0.0, 0.1, 0.2, 0.3]),\n",
        "        \"activation\": best_family[\"activation\"],\n",
        "        \"lr\": 10 ** random.uniform(-4, -2.7),\n",
        "        \"loss\": random.choice([\"huber\", \"mse\"]),\n",
        "        \"epochs\": 20\n",
        "    }\n",
        "    mae_, mse_, rmse_, r2_ = train_one_experiment(cfg)\n",
        "    tuning_rows.append([cfg[\"name\"], cfg[\"dropout\"], cfg[\"lr\"], cfg[\"loss\"], mae_, mse_, rmse_, r2_])\n",
        "\n",
        "tuning_df = pd.DataFrame(tuning_rows, columns=[\"Run\",\"dropout\",\"lr\",\"loss\",\"MAE\",\"MSE\",\"RMSE\",\"R2\"]).sort_values(\"MAE\")\n",
        "tuning_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observati**: Pentru această problemă, MAE a fost ales drept metrică principală de comparație, deoarece oferă o interpretare directă în unități reale (ore lucrate pe săptămână).\n",
        "Din această perspectivă, modelul E1_baseline_64_32_huber și E2_128_64_huber oferă performanțe comparabile, însă modelul E3_128_64_drop02_huber prezintă cel mai bun echilibru între eroare și capacitate de generalizare.\n",
        "Rezultatele arată că arhitecturi mai complexe nu garantează automat performanțe mai bune și că tehnicile de regularizare, precum dropout, pot avea un impact pozitiv asupra generalizării."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tabel final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Experiment</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E1_baseline_64_32_huber</td>\n",
              "      <td>7.301157</td>\n",
              "      <td>125.892380</td>\n",
              "      <td>11.220177</td>\n",
              "      <td>0.173395</td>\n",
              "      <td>Experiment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E2_128_64_huber</td>\n",
              "      <td>7.311493</td>\n",
              "      <td>124.779305</td>\n",
              "      <td>11.170466</td>\n",
              "      <td>0.180704</td>\n",
              "      <td>Experiment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T3</td>\n",
              "      <td>7.356822</td>\n",
              "      <td>133.174011</td>\n",
              "      <td>11.540104</td>\n",
              "      <td>0.125584</td>\n",
              "      <td>Tuning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E3_128_64_drop02_huber</td>\n",
              "      <td>7.393404</td>\n",
              "      <td>120.288048</td>\n",
              "      <td>10.967591</td>\n",
              "      <td>0.210193</td>\n",
              "      <td>Experiment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>T7</td>\n",
              "      <td>7.431906</td>\n",
              "      <td>124.447693</td>\n",
              "      <td>11.155613</td>\n",
              "      <td>0.182881</td>\n",
              "      <td>Tuning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>T5</td>\n",
              "      <td>7.442598</td>\n",
              "      <td>120.152725</td>\n",
              "      <td>10.961420</td>\n",
              "      <td>0.211082</td>\n",
              "      <td>Tuning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>T8</td>\n",
              "      <td>7.469151</td>\n",
              "      <td>120.335854</td>\n",
              "      <td>10.969770</td>\n",
              "      <td>0.209879</td>\n",
              "      <td>Tuning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>T4</td>\n",
              "      <td>7.541051</td>\n",
              "      <td>137.587830</td>\n",
              "      <td>11.729784</td>\n",
              "      <td>0.096603</td>\n",
              "      <td>Tuning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>T2</td>\n",
              "      <td>7.572160</td>\n",
              "      <td>118.633736</td>\n",
              "      <td>10.891911</td>\n",
              "      <td>0.221055</td>\n",
              "      <td>Tuning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>T1</td>\n",
              "      <td>7.618897</td>\n",
              "      <td>118.461464</td>\n",
              "      <td>10.884000</td>\n",
              "      <td>0.222186</td>\n",
              "      <td>Tuning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>E4_128_64_mse</td>\n",
              "      <td>7.676962</td>\n",
              "      <td>118.711754</td>\n",
              "      <td>10.895492</td>\n",
              "      <td>0.220543</td>\n",
              "      <td>Experiment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>T6</td>\n",
              "      <td>7.694831</td>\n",
              "      <td>131.563385</td>\n",
              "      <td>11.470108</td>\n",
              "      <td>0.136160</td>\n",
              "      <td>Tuning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Experiment       MAE         MSE       RMSE        R2  \\\n",
              "0   E1_baseline_64_32_huber  7.301157  125.892380  11.220177  0.173395   \n",
              "1           E2_128_64_huber  7.311493  124.779305  11.170466  0.180704   \n",
              "4                        T3  7.356822  133.174011  11.540104  0.125584   \n",
              "2    E3_128_64_drop02_huber  7.393404  120.288048  10.967591  0.210193   \n",
              "5                        T7  7.431906  124.447693  11.155613  0.182881   \n",
              "6                        T5  7.442598  120.152725  10.961420  0.211082   \n",
              "7                        T8  7.469151  120.335854  10.969770  0.209879   \n",
              "8                        T4  7.541051  137.587830  11.729784  0.096603   \n",
              "9                        T2  7.572160  118.633736  10.891911  0.221055   \n",
              "10                       T1  7.618897  118.461464  10.884000  0.222186   \n",
              "3             E4_128_64_mse  7.676962  118.711754  10.895492  0.220543   \n",
              "11                       T6  7.694831  131.563385  11.470108  0.136160   \n",
              "\n",
              "          Type  \n",
              "0   Experiment  \n",
              "1   Experiment  \n",
              "4       Tuning  \n",
              "2   Experiment  \n",
              "5       Tuning  \n",
              "6       Tuning  \n",
              "7       Tuning  \n",
              "8       Tuning  \n",
              "9       Tuning  \n",
              "10      Tuning  \n",
              "3   Experiment  \n",
              "11      Tuning  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_results = pd.concat([\n",
        "    results_df.assign(Type=\"Experiment\"),\n",
        "    tuning_df.rename(columns={\"Run\":\"Experiment\"}).assign(Type=\"Tuning\")[[\"Experiment\",\"MAE\",\"MSE\",\"RMSE\",\"R2\",\"Type\"]]\n",
        "], ignore_index=True).sort_values([\"MAE\",\"Type\"])\n",
        "\n",
        "all_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observati**: Se observă că diferențele de performanță între modelele experimentale și cele obținute prin tuning sunt relativ reduse, indicând faptul că arhitectura de bază este deja bine adaptată problemei.\n",
        "\n",
        "Cele mai bune rezultate (MAE ≈ 7.30) sunt obținute de modelele:\n",
        "\n",
        "- E1_baseline_64_32_huber\n",
        "\n",
        "- E2_128_64_huber\n",
        "\n",
        "Introducerea procesului de hyperparameter tuning nu a condus la îmbunătățiri semnificative față de modelele experimentale, sugerând că performanța este limitată și de caracteristicile datasetului.\n",
        "\n",
        "Modelele cu performanțe mai slabe (de exemplu, T1 și T4) evidențiază sensibilitatea Neural Networks la alegeri nepotrivite ale hiperparametrilor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Îmbunătățiri potențiale și direcții viitoare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Există mai multe direcții care ar putea fi explorate pentru a îmbunătăți performanța modelului:\n",
        "\n",
        "- Utilizarea embedding-urilor pentru variabilele categorice cu cardinalitate mare, în locul encodării one-hot, pentru a reduce dimensionalitatea și a crește eficiența modelului.\n",
        "\n",
        "- Aplicarea tehnicilor de early stopping și ajustare dinamică a ratei de învățare (learning rate scheduling) pentru a reduce timpul de antrenare și a preveni supra-antrenarea.\n",
        "\n",
        "- Realizarea unui proces de hyperparameter tuning mai extins, folosind metode precum Random Search sau Bayesian Optimization.\n",
        "\n",
        "- Testarea unor arhitecturi mai profunde sau utilizarea batch normalization pentru o stabilitate mai bună a antrenării.\n",
        "\n",
        "- Compararea performanței cu modele tradiționale de machine learning suplimentare, utilizate ca baseline-uri de referință."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Concluzie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "În cadrul acestui proiect a fost dezvoltat un model de regresie bazat pe Neural Networks pentru estimarea numărului de ore lucrate pe săptămână (hours-per-week) folosind datasetul Census. Datele au fost preprocesate anterior, iar setul de antrenare a fost împărțit în seturi de train, validation și test, pentru a asigura o evaluare corectă a performanței modelului.\n",
        "\n",
        "A fost implementat un model de bază (baseline), care a oferit un punct de referință pentru experimentele ulterioare. Au fost testate diferite arhitecturi și funcții de pierdere, iar performanța modelelor a fost evaluată folosind metrici standard de regresie, precum MAE, MSE, RMSE și R². Dintre acestea, MAE a fost aleasă ca metrică principală datorită interpretabilității sale directe.\n",
        "\n",
        "Rezultatele obținute arată că modelele mai complexe și procesul de hyperparameter tuning au adus îmbunătățiri limitate față de modelul de bază, sugerând că performanța este influențată în mare măsură de caracteristicile datasetului. Cu toate acestea, modelul Neural Network ales demonstrează o capacitate rezonabilă de generalizare și reprezintă o soluție viabilă pentru această problemă de regresie."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
